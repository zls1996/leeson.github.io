{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"Spring Aop源码学习","slug":"Spring-Aop源码学习","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T05:51:53.536Z","comments":true,"path":"2019/08/24/Spring-Aop源码学习/","link":"","permalink":"http://yoursite.com/2019/08/24/Spring-Aop源码学习/","excerpt":"","text":"","categories":[],"tags":[{"name":"Spring-AOP","slug":"Spring-AOP","permalink":"http://yoursite.com/tags/Spring-AOP/"}]},{"title":"深入理解计算机系统学习笔记","slug":"css：app","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:00:39.424Z","comments":true,"path":"2019/08/24/css：app/","link":"","permalink":"http://yoursite.com/2019/08/24/css：app/","excerpt":"计算机系统​ 从hello.c到hello.exe/hello.sh的编译过程​ 为了能够在系统上运行hello.c程序，每条c语句都必须被其他程序转换成一系列的低级机器语言指令。然后这种机器指令按照一种特定的格式打好包，就形成了可执行目标程序，可执行目标程序以二进制磁盘文件的形式存放起来。 ​ 计算机执行机器代码，用字节序列编码低级的操作，包括处理数据、管理内存、读写存取设备上的数据，以及利用网络通信，编译器基于编程语言的规则、目标机器的指令集和操作系统遵循的惯例，经过一系列的阶段生成机器代码。 GCC C语言编译器以汇编代码的形式产生输出，汇编代码是机器代码的文本表示，给出程序中的每一条指令。然后GCC调用汇编器和链接器，根据汇编代码生成可执行的机器代码。 ​ 机器执行的程序就是字节序列，它是一系列指令的编码，机器对于产生这些指令的源代码一无所知。","text":"计算机系统​ 从hello.c到hello.exe/hello.sh的编译过程​ 为了能够在系统上运行hello.c程序，每条c语句都必须被其他程序转换成一系列的低级机器语言指令。然后这种机器指令按照一种特定的格式打好包，就形成了可执行目标程序，可执行目标程序以二进制磁盘文件的形式存放起来。 ​ 计算机执行机器代码，用字节序列编码低级的操作，包括处理数据、管理内存、读写存取设备上的数据，以及利用网络通信，编译器基于编程语言的规则、目标机器的指令集和操作系统遵循的惯例，经过一系列的阶段生成机器代码。 GCC C语言编译器以汇编代码的形式产生输出，汇编代码是机器代码的文本表示，给出程序中的每一条指令。然后GCC调用汇编器和链接器，根据汇编代码生成可执行的机器代码。 ​ 机器执行的程序就是字节序列，它是一系列指令的编码，机器对于产生这些指令的源代码一无所知。 编译系统​ 编译系统(Compilation system)由四步构成：预处理器、编译器、汇编器、链接器组成。 计算机系统硬件组成 总线 ​ 贯穿整个系统的是一组电子管道，称为总线。总线携带信息字节并负责在各个组件之间传递。通常总线被设计成传递固定长的字节块，也就是字(word)。字中的字节数（即字长）是一个基本的系统参数，各个系统中都不尽相同。现在的大多数机器字长要么是4个字节(32为系统)，要么是8个字节（64位）。 I/O设备 I/O设备是系统与外部世界的联系通道。每个i/o设备都通过一个控制器或者适配器与I/O总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是I/O设备本身或者系统的主印制电路板上的芯片组。而适配器则是一块插在主板插槽上的卡。无论如何，它们的功能都是在I/O总线和I/O设备之间传递信息。 主存 主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序运行时刻数据。 CPU 处理器，解释或执行存储在主存中指令的引擎。处理器的核心是一个大小为一个字的存储设备（或寄存器），称为程序计数器（PC）。在任何时刻，PC都指向主存中的某条机器语言指令。 从系统通电开始，直到系统断电，处理器一直在不断地执行程序计数器指向的指令，再更新程序计数器，使其指向下一条指令。 高速缓存​ 程序和程序数据最初是被存放在磁盘上 。当程序被加载时，它们复制到主存，当处理器运行程序时，指令又从主存复制到处理器。从程序员的角度来看，复制就是开销，减慢了程序“真正的工作”。因此，系统设计者得一个主要目标就是使这些复制操作尽可能快的执行。 ​ 根据机械原理，较大的存储设备要比较小的存储设备运行的慢，而快速设备的造价远高于同类的低速设备。类似地，一个典型的寄存器文件只存储几百字节的信息。而主存中可存放十几亿个字节。但是，处理器从寄存器中读取数据比从主存中读取要快100倍。 ​ 针对这种处理器与主存之间速度的差异，系统设计者采用了更小更快的存储设备，称为高速缓存寄存器(cache memory)，作为暂存的集结领域，存放处理器近期可能会需要的信息。 信息存储​ 大多数计算机都采用8位的块，或者称为字节，作为最小的可寻址的内存单位，而不是访问内存中单独的位。机器级程序将内存视为非常大的字节数组，称为虚拟内存(virtual memory)。内存的每个字节都用一个唯一的数字来标识，称为它的地址，所有可能地址的空间的集合就称为虚拟地址空间。 ​ 当我们使用高级语言编程时(C、C++、Java)，机器屏蔽了程序的细节，即机器级的实现。与此相反，当用汇编代码编程的时候，程序员必须指定程序用来执行计算的低级指令。高级语言提供的抽象级别比较高，大多数时候，在这个级别上工作的效率比较高，也更可靠。编译器提供的类型检查能帮助我们发现许多程序错误，并能够保证一致的方式来引用和处理数据。通常情况下，使用现代的优化编译器产生的代码至少于一个熟练的汇编语言程序员手工代码一样有效。最大的优点是，用高级语言编写的程序可以在很多不同的机器上编译与运行。而汇编代码则是与特定机器密切相关的。 ​ 对于严谨的程序员而言，能够阅读和理解汇编代码仍然是一项很重要的功能。通常将尝试源代码的各种形式，每次编译并检查产生的汇编代码，从而了解程序的运行情况。 处理器体系结构​ 处理器必须执行一系列指令，每条指令执行某个简单操作，例如两个数相加。指令被编码为由一个或多个字节序列组成的二进制格式。一个处理器所支持的指令和指令的字节级编码称为它的指令级体系结构(Instruction-Set Architectute, ISA)，不同的处理器，都有着不同的ISA。一个程序被编译成在一种机器上运行，就不能在另外一台机器上执行。 ​ ISA模型看起来应该是顺序指令执行，也就是先取出一条指令，等到它执行完毕，再开始下一条。然而，与一个时刻只执行一条指令相比，通过同时处理多条指令的不同部分，处理器可以获得更高的性能。为了保证处理器能够得到同顺序执行的结果，人们采用了一些特殊的机制。 存储器层次结构​ CPU执行指令，而存储器系统为CPU存放指令和数据。存储器系统是一个具有不同容量、成本和访问时间的存储设备的层次结构。CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存存储器作为一部分存储在相对慢速的主存储器中数据和指令的缓冲区域。主存缓存在容量较大、慢速磁盘上的数据，而这些磁盘上常常又做为存储在通过网络连接的其他机器的磁盘或者磁带上的数据的缓冲区域。","categories":[],"tags":[{"name":"计算机系统","slug":"计算机系统","permalink":"http://yoursite.com/tags/计算机系统/"}]},{"title":"深入理解计算机系统学习笔记","slug":"docker学习","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:01:02.066Z","comments":true,"path":"2019/08/24/docker学习/","link":"","permalink":"http://yoursite.com/2019/08/24/docker学习/","excerpt":"Docker学习docker常用命令​ docker pull : 获取image ​ docker build : 创建image -t:image的标签 ​ docker images：列出images ​ docker run： 运行container ​ docker ps: 列出运行的container ​ docker rm:删除container ​ docker rmi: 删除image ​ docker cp : 在host和container之间拷贝文件 ​ docker commit : 保存改动为新的image","text":"Docker学习docker常用命令​ docker pull : 获取image ​ docker build : 创建image -t:image的标签 ​ docker images：列出images ​ docker run： 运行container ​ docker ps: 列出运行的container ​ docker rm:删除container ​ docker rmi: 删除image ​ docker cp : 在host和container之间拷贝文件 ​ docker commit : 保存改动为新的image Dockerfile​ Dockerfile是一个文本文件，其中包含了一条条的指令(instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 ​ 举例创建nginx镜像如下: 12345$ mkdir mynginx$ cd ./mynginx$ touch Dockerfile Dockerfile文件内容如下： 12FROM nginxRUN echo '&lt;h1&gt;Hello Docker&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html RUN指令​ RUN指令用来执行命令行命令。由于命令行的强大能力，RUN指令在定制镜像时是最常用的指令之一。其格式有两种： shell格式，如上代码所示 1RUN chmod +x /usr/share/nginx exec格式 ： 1RUN [\"可执行文件\"， \"参数1\"， \"参数2\" ] COPY复制指令​ COPY指令将构建上下文目录中源路径中的文件(package.json)复制到新的一层镜像内的目标路径位置（/usr/src/app）中。 1COPY package.json /usr/src/app 源文件可以是多个，甚至可以是通配符，其通配符要符合GO的filepath.Match规则，比如： 12COPY home* /mydir/COPY hom?.txt /mydir/ 使用COPY指令，源文件的各种元数据都会保留。比如读写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。 ADD添加指令​ ADD和COPY的格式与性质基本一致。但是在COPY基础上添加了一些功能。一般最适用的情况，就是自动解压缩的情形。 12FROM scratchADD ubuntu-xenial-core-clouding-amd64-root.tar.gz / ADD指令自动将自动解压缩到目标路径中。 CMD指令​ 用于指定默认容器主进程的启动命令。Docker不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机那样用upstart/systemd去启动后台服务，在容器中没有后台服务的概念。 1CMD [\"nginx\", \"-g\", \"daemon off\"] ENTRYPOINT入口​ ENTRYPOINT的格式和RUN指令一样，分为exec和shell格式。 ​ ENTRYPOINT的目的和CMD一样，都是在容器启动时，指定容器启动程序以及参数。ENTRYPOINT在运行时也可以被替代，不过比CMD相比要略显繁琐，需要通过docker run 的参数 –entrypoint 来指定。 1ENTRYPOINT [\"java\", \"-Djava.security.egd=file:/dev/./urandom\", \"-jar\", \"/app.jar\"] ARG构建参数​ 设置环境变量。ARG所设置的构建环境变量的变量，在将来容器运行时是不会存在这些环境变量的。 1ARG JAR_FILE VOLUME定义匿名卷​ 容器在运行时，应该尽量保持容器存储层不发生写操作，对于数据库类型需要保存动态数据的应用，其数据库文件应该保存在卷(volume)中、为了防止运行时用户忘记将动态文件所保存的目录挂载为卷，在Dockerfile中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 ​ 镜像上下文(Context)​ docker镜像构建指令 1docker build -t nginx:latest . ​ docker build -t 命令最后会有一个 . 。表示当前目录，指定上下文路径。 ​ 上下文： 用户本地构建时，会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将该路径下的所有内容打包，然后上传到docker引擎。这样docker引擎收到这个上下文包后，展开就会获得构建镜像所需一切的文件。 1COPY ./package.json /app/ ​ 这条命令并不是要复制执行docker build 命令所在目录下的package.json,也不是复制Dockerfile所在目录下的package.json,而是复制上下文（Context）目录下的package.json。 docker-composeswarm","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"分布式系统学习笔记","slug":"分布式","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:01:21.004Z","comments":true,"path":"2019/08/24/分布式/","link":"","permalink":"http://yoursite.com/2019/08/24/分布式/","excerpt":"分布式系统是由多个节点通过网络连接在一起并通过消息的传递来进行协调的系统。 分布式系统的难点 缺乏全局时钟：每个节点都有自己的时钟，通过相互发送消息进行协调时，如果仍然依赖时序，会相对比较难处理。 面对故障独立性。 单点故障 事务的挑战","text":"分布式系统是由多个节点通过网络连接在一起并通过消息的传递来进行协调的系统。 分布式系统的难点 缺乏全局时钟：每个节点都有自己的时钟，通过相互发送消息进行协调时，如果仍然依赖时序，会相对比较难处理。 面对故障独立性。 单点故障 事务的挑战 消息中间件的好处​ 异步、解耦、削峰 从功能角度看，分布式框架通常包括两个重要功能：服务治理中心和服务注册中心。 服务注册中心负责服务的发布和通知，通常支持对等集群部署，某一个服务注册中心宕机并不会导致整个服务注册中心集群不可用。即使整个服务注册中心全部宕机，也只影响新服务的注册和发布，不影响已经发布的服务的访问。 服务治理中心通常包含服务治理接口和服务治理portal，架构师、测试人员和系统运维人员通过服务治理Portal对服务的运行状态、历史数据、健康度和调用关系等进行可视化的分析和维护，目标就是要优化服务，防止服务架构腐化，保证服务高质量运行。 应用服务化后的性能​ 应用服务化之后，由原来的本地API调用变成跨进程远程服务调用，网络通信、消息序列化和反序列化、反射调用和动态代理都会导致性能损耗、时延增加。对于复杂的应用，例如购买商品，后台会涉及到100多个服务调用。如果服务框架的性能比较差，时延将会放大数十倍，因此分布式服务框架的性能指标非常重要。","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/分布式/"}]},{"title":"深入理解计算机系统学习笔记","slug":"Go","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:00:47.391Z","comments":true,"path":"2019/08/24/Go/","link":"","permalink":"http://yoursite.com/2019/08/24/Go/","excerpt":"Go语言特性 开源 静态类型和编译型语言 跨平台 自动垃圾回收 原生的并发编程 完善的构建工具 多编程范式。（支持函数式编程、面向对象编程） 代码风格强制统一 （go format） 高效的编程和运行 丰富的标准库 函数标识符​ go函数标识符首字母的大小写控制着对应程序实体的访问权限。如果标识符的首字符是大写，那么它所对应的程序实体就可以被本代码包之外的代码访问到，也称为可导出的或公开的。否则，对应的程序实体就只能被本包内的代码访问到，也称为不可导出的或包私有的。","text":"Go语言特性 开源 静态类型和编译型语言 跨平台 自动垃圾回收 原生的并发编程 完善的构建工具 多编程范式。（支持函数式编程、面向对象编程） 代码风格强制统一 （go format） 高效的编程和运行 丰富的标准库 函数标识符​ go函数标识符首字母的大小写控制着对应程序实体的访问权限。如果标识符的首字符是大写，那么它所对应的程序实体就可以被本代码包之外的代码访问到，也称为可导出的或公开的。否则，对应的程序实体就只能被本包内的代码访问到，也称为不可导出的或包私有的。 Go标准命令 build: 用于编译指定的代码或者GO语言源码文件。命令源码文件会被编译成可执行文件(windows对应exe文件， linux对应sh文件)，并存放到命令执行的目录或者指定目录下。而库源码文件被编译后，则不会在非临时目录中留下任何文件。 clean： 用于清除因执行其他go命令而遗留下来的临时目录和文件。 doc： 用于显示go语言代码包以及程序实体的文档 env： 用于打印GO语言相关的环境信息 fix： 用于修正指定代码包的源码文件中包含的过时语法或者代码调用。这使得我们在升级go语言版本时，可以非常方便同步升级程序。 fmt： 用于格式化指定代码包中的GO源码文件。实际上，它是通过gofmt命令来实现功能的。 generate： 用于识别指定代码包中源码文件中的go:generate注释，并执行其携带的任意命令。该命令独立于go语言标准的编译和安装体系。 get： 下载、编译并安装指定的代码及其依赖包。 install： 用于编译并安装指定的代码包及其依赖包。安装命令源码文件之后，代码所在的工作区目录的bin子目录，或者当前环境变量GOBIN指向的目录会生成所对应的可执行文件。 list： 用于显示指定代码包中的信息 run： 用于编译并运行指定的命令源码文件。当不想生成可执行文件而直接运行命令源码文件时，就需要使用它。 tool：用于运行GO语言的特殊工具 vet： 用于检查指定代码包的GO语言源码，并报告发现可疑代码问题。 version： GO语言版本以及环境信息。 Go语言中，new()和make()的区别？​ new是内建函数，定义如下： 1func new(Type) *Type 官方文档对于其描述是：内建函数new用来分配内存，它的第一个参数是一个类型，不是一个值，它的返回值是一个指向新的分配类型零值的指针。 make也是内建函数，官方对它的描述是：内建函数make用来为slice，map和chan类型分配内存和初始化一个对象，跟new类似，第一个参数也是一个类型而不是一个值，跟new不同的是，make返回类型的引用而不是指针，返回值也依赖于具体传入的类型。 总结：new的作用就是初始化一个指向类型的指针，make的作用为slice，map或chan初始化并返回引用T。 Go语言中的引用类型有：映射（Map）、数组切片(slice)、通道（channel）,方法和函数。 在使用指针之后，本来是值传递的整数类型在函数或者方法中修改会影响到原变量的值。 Go中的值传递​ Go语言中所有的传参都是值传递(传递值)，都是一个副本，一个拷贝。因为拷贝的内容有时候是非引用类型(int ,string, struct这些)，这样就在函数中无法修改原内容数据；有的是引用类型（指针、map、slice、chan等），这样就可以修改原内容数据。 defer​ Go语言的defer语句会将后面跟随的语句进行延迟处理。在defer归属的函数即将返回时，将延迟处理的语句按照defer的逆序来进行执行。也就是说，先被defer的语句最后被执行，最后被defer的语句，最先被执行。 Go语言处理运行时错误​ Go语言的错误处理思想及其设计包含一下特征： 一个可能造成错误的函数，需要返回值中返回一个错误接口。如果调用时成功的，错误接口将返回nil，否则将返回错误。 在函数调用后需要检查错误，如果发生错误，进行必要的错误处理。 Go语言没有类似于Java的异常处理机制，虽然可以使用defer、panic、recover来模拟，但是官方并不主张这么做。 Go语言中的空接口​ 空接口是接口类型的特殊形式，空接口没有任何方法，因此任何类型都无需实现空接口。从实现的角度来看，任何值都满足这个接口的需求。因此空接口类型可以保存任何值，也可以从空接口中取出值。 ​ 空接口类型类似于C#或者Java中的object。 ​ 空接口的内部实现保存了对象的类型和指针。使用空接口保存一个数据的过程会比直接调用数据对应类型的变量稍慢。因此在开发中，应在需要中使用空接口，而不是在所有地方使用空接口。 Go并发​ Go语言通过编译器运行时(runtime)，从语言上支持了并发的特性。Go语言的并发通过goroutine特性完成。goroutine类似于线程，但是可以根据需要创建多个和goroutine并发工作。goroutine是由Go语言的运行时调度完成，而线程是由操作系统调度完成。 ​ Go语言还通过提供channel在多个goroutine之间进行通信。goroutine和channel是go语言秉承的CSP(Communicating Sequential Process)并发模式的重要实现基础。 ​ goroutine的概念类似于线程，但是goroutine是由Go程序运行时的调度和管理。Go程序会智能地将goroutine中的任务合理地分配给每个CPU。 ​ Go语言从main包的main函数开始，在程序启动时，Go程序会为main函数创建一个默认的goroutine。 ​ Go语言中使用go关键字为函数创建一个goroutine。一个函数可以创建多个goroutine，一个goroutine未必对应一个函数。 ​ 在Go程序运行时(runtime)实现了一个小型的任务管理器。这套调度器的工作原理类似于操作系统调度线程，Go程序调度器可以高效地将CPU资源分配给每一个任务。传统逻辑中，开发者需要维护线程池中与CPU核心数量的对应关系。同样地，Go也可以通过runtime.GOMAXPROCS()函数做到。` 1runtime.GOMAXPROCS(runtime.NumCPU()) ​ 单纯将函数并发执行是没有意义的。函数与函数之间需要交换数据才能体现并发执行的意义。虽然可以使用共享内存进行数据交换，但是在共享内存在不同的goroutine之间容易产生竟态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 ​ Go语言中的通道(channel)是一种特殊的类型。在任何时候，同时只能有一个goroutine访问通道进行发送和获取数据。goroutine间通过通道就可以进行通信。通道就像一个传送带或队列，总是遵循先进先出的规则，保证收发数据的正确性。 Go等待組(waitgroup)​ 除了可以使用通道(channel)和互斥锁进行两个并发程序之间的同步之外，还可以使用等待组(waitgroup)进行多个任务的同步，类似于java的CyclicBarrier。等待组可以保证在并发环境中完成指定数量的任务。 ​ Go的跨平台​ go并没有真正意义上的实现跨平台。go程序先被编译成机器码，这个机器码是针对特定的平台来生成的机器码，不同的平台要重新编译，编译出来的程序能够直接运行（类似于C/C++，但C/C++需要自己管理内存）。与java不同，java程序需要jvm本地才能运行，但是java对于所有的平台都只需要编译一次，jvm底层完成了平台的相应处理（不同平台有着不同的jvm）。 Go切片1sli := make([]type, len, cap) ​ 第一个参数：数组类型 ​ 第二个参数：数组长度 ​ 第三个参数：数组容量 Go管道(channel)​ 当一个资源需要在goroutine之间共享时，通道在goroutine之间架起了一个管道，并提供了确保同步交换数据的机制。 123456789//创建一个无缓冲通道unBufferedChannel := make(chan string)//创建一个缓冲通道bufferedChannel := make(chan string , 10)//向通道发送字符串unBufferedChannel &lt;- \"Hello World\"//向通道中取出数据value := &lt;- unBufferedChannel 无缓冲管道​ 无缓冲通道(unbuffered channel)是指在接收前没有能力保存任何值的通道。这种类型的通道要求发送goroutine和接收goroutine同时准备好，才能完成发送和接收操作。如果两个goroutine没有同时准备好，通道就会导致执行发送或接收操作的goroutine阻塞等待。这种对通道进行发送和接收的交互行为本身就是同步的。 ​ 有缓冲管道​ 有缓冲管道是一种在被接收前能存储一个或者多个值的通道。这种类型的通道并不强制要求goroutine之间必须同时完成接收和发送。通道会阻塞发送和接收动作的条件也会不同。只有在通道中没有要接收的值时，才会阻塞。只有在通道没有可用缓冲区容纳被发送的值时，发送动作才会阻塞。 Go的并发机制​ go并发宗旨：不要用共享内存的方式来进行通信。作为替代，应该以通信作为手段来共享内存。 go不推荐用共享内存的方式来传递数据，而推荐使用channel。channel用来在多个goroutine之间传递数据，并且还会保证整个过程的并发安全性。","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"http://yoursite.com/tags/Go/"}]},{"title":"操作系统学习 笔记","slug":"操作系统","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:01:13.515Z","comments":true,"path":"2019/08/24/操作系统/","link":"","permalink":"http://yoursite.com/2019/08/24/操作系统/","excerpt":"操作系统内存管理​ 计算机分层存储器体系(memory hierarchy)：计算机有若干兆快速、昂贵的高速缓存(cache)、数千兆（G）速度与价格适中的同样易失性的内存、以及几TB的低速、廉价、非易失性的磁盘存储。 ​ 最底层的高速缓存由硬件来直接管理。 无存储器抽象的缺点​ 最简单的存储器抽象就是没有抽象。每个程序直接访问物理内存，指令如下： 1MOV REGISTER1, 1000 ​ 计算机会直接将位置1000的物理内存上的内容直接移到REGISTER1上。呈现给编程人员的存储器模型就是简单的物理内存。在这种情况下，想要在内存中同时运行两个程序是不可能的。 存储器抽象： 地址空间​ 想要使得多个应用程序同时处于内存中不受影响，需要解决两个问题：保护和重定向。地址空间就像进程中创建了一类抽象的CPU用以运行程序一样，地址空间为程序创造了一种抽象的内存。地址空间是一个进程用于寻址内存的一套地址集合。每个进程都有自己的地址空间，并且这个地址空间独立于其他的地址空间。 ​ 比较难的是给每个程序一个自己独有的地址空间，使得一个程序中的地址28与另一个程序中的地址28物理地址不同。所解决的办法就是采用动态重定位。动态重定位就是把每个程序的地址空间映射到物理地址的不同部分。所实现的方法就是在每个CPU中配置了两个特殊硬件寄存器，通常叫做基址寄存器和界限寄存器。当一个程序运行时，程序的初始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中。 ​ 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU硬件会把地址发送到内存总线之前，自动把基址值加到进程发出的地址值上。如果访问的地址超过了界限，会产生错误并终止访问。 ​ 使用基址寄存器和界限寄存器是给每个进程提供地址空间非常容易的方法，因为每个内存地址在送到内存之前，都会自动加上基址寄存器的内容。 ​ 使用基址寄存器和界限寄存器重定向的缺点是：每次访问内存都需要进行加法和比较运算。","text":"操作系统内存管理​ 计算机分层存储器体系(memory hierarchy)：计算机有若干兆快速、昂贵的高速缓存(cache)、数千兆（G）速度与价格适中的同样易失性的内存、以及几TB的低速、廉价、非易失性的磁盘存储。 ​ 最底层的高速缓存由硬件来直接管理。 无存储器抽象的缺点​ 最简单的存储器抽象就是没有抽象。每个程序直接访问物理内存，指令如下： 1MOV REGISTER1, 1000 ​ 计算机会直接将位置1000的物理内存上的内容直接移到REGISTER1上。呈现给编程人员的存储器模型就是简单的物理内存。在这种情况下，想要在内存中同时运行两个程序是不可能的。 存储器抽象： 地址空间​ 想要使得多个应用程序同时处于内存中不受影响，需要解决两个问题：保护和重定向。地址空间就像进程中创建了一类抽象的CPU用以运行程序一样，地址空间为程序创造了一种抽象的内存。地址空间是一个进程用于寻址内存的一套地址集合。每个进程都有自己的地址空间，并且这个地址空间独立于其他的地址空间。 ​ 比较难的是给每个程序一个自己独有的地址空间，使得一个程序中的地址28与另一个程序中的地址28物理地址不同。所解决的办法就是采用动态重定位。动态重定位就是把每个程序的地址空间映射到物理地址的不同部分。所实现的方法就是在每个CPU中配置了两个特殊硬件寄存器，通常叫做基址寄存器和界限寄存器。当一个程序运行时，程序的初始物理地址装载到基址寄存器中，程序的长度装载到界限寄存器中。 ​ 每次一个进程访问内存，取一条指令，读或写一个数据字，CPU硬件会把地址发送到内存总线之前，自动把基址值加到进程发出的地址值上。如果访问的地址超过了界限，会产生错误并终止访问。 ​ 使用基址寄存器和界限寄存器是给每个进程提供地址空间非常容易的方法，因为每个内存地址在送到内存之前，都会自动加上基址寄存器的内容。 ​ 使用基址寄存器和界限寄存器重定向的缺点是：每次访问内存都需要进行加法和比较运算。 交换技术​ 交换技术：把一个进程完整调入内存，使该进程运行一段时间，然后将它存回磁盘。空闲进程主要存储在磁盘上，所以当他们不运行时就不会占用内存。 ​ 交换在内存中产生了多个空闲区，通过把所有的进程尽可能向下移动，有可能将这些小的空闲区合并成一大块。这个技术称为内存紧缩。通常不会进行这个操作，因为会耗费大量的CPU时间。例如，有一台16GB内存的计算机每8ns复制8个字节，那么它紧缩全部，需要花费16s的时间。 ​ 许多程序设计语言都允许从堆中动态分配内存，那么当进程空间试图增长时，就会出现问题。为了减少因为内存不够而引起的进程交换和移动所产生的开销，一种可用的方法是：当换入或移动进程时为它分配一些额外的内存。 ​ 在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方法可以跟踪内存使用情况：位图和空闲区链表。 ​ 空闲链表存储管理：最佳适配法、首次适应法、最差适配法、快速适配法 ​ 虚拟内存​ 虚拟内存使得程序在只有一部分被调入内存的情况下运行。虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割诚多个块，每一块被称为页或者页面，每一页拥有连续的地址范围。这些页被映射到物理内存，但是并不是所有的页面都必须在内存中才能运行程序。从某个角度来看，虚拟内存是对基址寄存器和界限寄存器的综合。 ​ 由程序产生的地址被称为虚拟地址。它们构成了一个虚拟地址空间（virtual address space）。在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用具有同样的地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到地址总线上，而是被送到内存管理单元（Memory Management Unit）上，MMU将虚拟地址直接映射为物理地址。 ​ 页表：页表的目的是把虚拟页面映射成页框。从数学角度看，页表是一个函数，它的参数是虚拟页号，结果是物理页框号。 ​ 页面置换算法：FIFO、最近最少使用、最近未使用、时钟页面置换算法、最优算法 分段：分页的虚拟内存都是一维的，虚拟地址从0到最大地址，一个地址接着另外一个地址。对许多问题来说，有两个或者多个独立的地址空间可能会比只有一个好得多。一个直观并且通用的方法是在机器上提供多个互相独立的称为段（segment）。每个段由一个或者多个最大的线性地址序列构成。段的长度在运行期间可以动态改变，比如，堆栈长度在数据压入时会增长，在数据弹出时又会被减小。​ 要在分段或者二维的存储器中指示一个地址，程序必须提供两个部分地址：一个段号和一个段内地址。段是一个逻辑实体，程序员知道这点并且把它作为一个逻辑实体来使用。 ​ 分段有助于几个进程之间共享过程和数据。例如，在分段系统中，可以把图像库放到一个单独的段中由各个进程共享，从而不再需要在每个进程的地址空间中都保存一份。 文件系统​ 就像操作系统提取处理器的概念来建立进程的抽象，以及提取物理存储器的概念来建立进程地址空间的抽象那样，我们可以用一个新的抽象-文件，来解决一些存储的问题。 ​ 文件时进程创建的信息逻辑单元。一个磁盘通常包含几千个甚至几百万个文件，每个文件时独立于其他文件的，唯一不同的是文件对磁盘的建模，而非对RAM的建模。事实上，如果能把每个文件看成一个地址空间，那么就能理解文件的本质了。 ​ 文件结构​ 文件可以有多种构造方式，包括字节序列、记录序列、树。事实上操作系统并不关心文件内容是什么，操作系统所见到的就是字节，其文件内容的任何含义只在用户程序中解释。Unix和Windows都采用这种方法。 ​ .指向当前目录，..指向上一级目录。 文件类型​ 包括普通文件和目录，unix还有字符特殊文件和块特殊文件。普通文件包括ASCII文件和二进制文件。文件系统通常提供目录或者文件夹用于记录文件的位置，在很多系统中，目录本身也是文件。目录包括以及目录系统和层次文件系统。 文件访问 顺序访问。进程从系统中可以从头开始按照顺序读取文件的全部字节和记录，但不能跳过某一些内容，也不能不按顺序读取。在存储介质是磁带而不是磁盘时，顺序访问是很不方便的。 随机访问：不按顺序读物文件中的字节或记录，或者按照关键字而不是按照位置来访问记录。可以通过read操作指定开始读取的位置。或者使用seek操作设置当前要读取的位置。 文件属性​ 文件都有数据和属性。另外还有文件创建时期、大小等附加信息。这些信息被称为文件属性(attribute)或者元数据(metadata)。 文件系统的实现​ 文件和目录是如何存储，磁盘空间是如何管理的，怎样使系统更加可靠稳定工作。 文件系统布局​ 文件系统存放在磁盘上。多数磁盘划分为一个或多个分区，每个分区有一个独立的文件系统。磁盘的0号扇区称为主引导记录（Master Boot Record）,用于指导计算机。在MBR的末尾是分区表。该表给出了每个分区的起始和结束地址。在计算机启动时， BIOS读取并执行MBR。MBR做的第一件事就是确定活动分区，读入它的第一个块，称为引导块(boot block)。引导块中的程序将装载该分区的操作系统。 文件的实现​ 文件存储的关键问题是记录各个文件分别用到哪些磁盘块。不同操作系统采用不同的方法。 连续分配： 把每个文件作为一连串连续数据块存储在磁盘上。读取性能高，但是删除部分块后，磁盘会变得零碎 链表分配：每个块的第一个字作为指向下一块的指针，块的其他部分存放数据。不会出现碎片问题，但是随机读取性能差；存储效率没有连续分配高。 inode节点：为每个文件赋予一个i节点，其中列出了文件属性和文件块的磁盘地址。给定i节点，就能找到文件的所有块。inode与真实的文件一一对应，用来记录这个文件的各个属性：权限、属性、所有者、创建时间、最近修改时间等等。 日志结构文件系统​ 由于CPU、内存等的发展速度越来越快，相对应的是磁盘速度却没得到快速发展。因此诞生了日志结构文件系统。日志结构文件系统的基本思路是：将整个磁盘结构化为一个日志。每隔一段时间，或有特殊需要时，被缓冲在内存中的所有未决的写操作都被放入到一个单独的段中，作为在日志末尾的一个邻接段写入磁盘。这些单独的段可能会包括i节点、目录快、数据块。 ​ 日志文件系统基于这种假设：文件被缓存在内存中，当缓存越来越多时，cache就会比较符合读的需求，结果就是，与磁盘的交互主要就限制在写操作。日志文件系统将所有的新信息以一种叫做log的连续结构写入磁盘。由于这种方式取消了几乎所有的寻道操作，因此极大地提高了写操作效率。log结构这种连续的属性也允许更快的崩溃恢复。 ​ Windows的NTFS、Linux的EXT3都使用日志文件系统。 虚拟文件系统​ 由于多种文件系统的存在，在实际应用中是明确可见的。因此绝大多数Unix操作系统都使用了虚拟文件系统概念将多种文件系统统一成一个有序的结构。关键的思想就是抽象出所有文件系统中共有的部分，并且将这部分代码放在单独的一层，该层调用底层的实际文件系统来具体管理数据。 虚拟化和云​ 沙盒： 沙盒是一种安全机制，为运行中的程序提供了隔离环境。通常是作为一些来源不可信、具有破坏力或者无法判断程序意图的程序提供实验之用。 虚拟化​ 虚拟化的主要思想是虚拟机监控程序(Virtual Machine Monitor VMM)，在同一个物理硬件中创建出具有多台的多虚拟机假象。","categories":[],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/tags/操作系统/"}]},{"title":"面试常见问题总结","slug":"面试高频考点","date":"2019-08-24T14:56:26.000Z","updated":"2019-08-25T06:01:29.526Z","comments":true,"path":"2019/08/24/面试高频考点/","link":"","permalink":"http://yoursite.com/2019/08/24/面试高频考点/","excerpt":"1、数据库Mysql数据库的索引（b、b+、hash索引、聚簇索引），数据库事务ACID、事务读的几种状态、索引失效问题、 乐观锁(MVCC)和悲观锁 数据库隔离级别 MyISAM和InnoDB区别 聚簇索引 数据库垂直、水平切分 数据库范式","text":"1、数据库Mysql数据库的索引（b、b+、hash索引、聚簇索引），数据库事务ACID、事务读的几种状态、索引失效问题、 乐观锁(MVCC)和悲观锁 数据库隔离级别 MyISAM和InnoDB区别 聚簇索引 数据库垂直、水平切分 数据库范式 什么是存储过程？​ 存储过程是一些预编译的sql语句。更加直白的讲，存储过程是一个记录集，它是由一些sql语句组成的代码块，这些sql语句代码像一个方法一样实现一个功能，然后再给这些代码块取一个名字，用到这个功能时候就可以直接调用了。 什么是视图？​ 视图是一张虚拟的表，具有和物理表相同的功能。可以对视图进行CRUD，视图通常是由多张表的行和列组成。对视图的操作不会影响到原有表。相比于多表联合查询，视图使得我们获取数据更加容易。 ACID answer： ​ A(Atomic): 原子性： 一个事务中的所有操作，要么全部完成，要么全部不完成。 ​ C(Consistency) : 一致性：在事务开始之前和事务开始之后，数据库的完整性没有被破坏，要么全部完成，要么全部不完成。 ​ I(Isolation) : 隔离性： 数据库允许多个并发事务同时对数据进行读写和修改的能力，隔离性可以防止多个并发执行时由于交叉执行而导致的数据不一致。 ​ D(Duration) : 持久性： 事务处理结束之后，对数据的修改是永久的，即时系统故障也不会丢失。 ​ answer： ​ 索引是一个排序的列表，在这个列表中，存储着索引的值和包含这个值的数据所在行的物理地址，在数据十分庞大的时候，索引可以大大加快查询的速度，这是因为使用索引后可以不用扫描全表来定位某行的数据，而是通过索引表来找到改行的数据物理地址，提升访问速度。Mysql主要提供的两种索引是：BTree索引和Hash索引。 ​ hash索引：在mysql中，只有memory引擎支持hash索引，hash索引是memory表的默认引擎。由于索引自己仅仅存储很短的值，所以，索引非常紧凑。hash索引仅仅包含hashcode和记录指针，所以，mysql不能通过使用索引来避免读取记录。但是，访问内存中的记录非常迅速的，不会对性能造成太大影响。 ​ hash索引的缺点：不能使用has h索引来进行排序；hash索引不支持键的部分匹配，因为索引值是通过整个索引值来计算hash值的。另外，hash索引只支持等值比较，例如=， In。但是用 &gt; 或&lt;时，使用该索引是无效的。 ​ 聚簇索引：聚簇索引保证了关键字的值相近的元祖存储的物理位置也相同，并且一个表只能有一个聚簇索引。聚簇索引的结构如下： ​ 可以发现：在聚簇索引的b树中，只有叶子节点包含了完整的元祖，而叶内节点仅仅只包含索引的主键的值。需要注意的是：InnoDB支持聚簇索引，而MyISAM不支持聚簇索引。如果在表中，不指定主键的话，InnoDB会用一个具有唯一的且非空值的索引来代替。如果不存在这样的索引，InnoDB就会定义一个隐藏的主键，然后对其建立聚簇索引。InnoDB按照聚簇索引的形式来存储数据，所以它的数据布局有着很大的不同。 ​ 聚簇索引中的每个叶子节点包含primary key的值，事务ID以及回滚指针，分别用于事务和MVCC。 ​ 为了提高聚簇索排序性能，最好的做法就是使用一个AUTO_Increment的列，这会保证记录按照顺序插入，而且能提高使用primary key进行连接和查询的性能。应该尽量避免随机的聚簇索引主键，比如字符串。 ​ 在使用InnoDB的引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段来作为主键。 ​ 索引的优化： 采用最左前缀匹配，一般把排序分组频率最高的列放在最左边。 数据库事务的并发问题： 脏读：事务A读取了B更新的数据，然后B回滚了该操作，那么A读到的数据就是脏数据。 不可重复读：首先A读取了某一行的值，然后B更新了该行的值，A再读，发现不一致。 幻读：A将数据库进行某个字段的全部更新操作，这时候B修改或新建了与A不一致的数据，然后A发现有数据不一致，以为没更新完毕。 注意：不可重复读和幻读经常容易混淆，不可重复读侧重于修改，而幻读侧重于新增或删除。解决不可重复读的思路是锁住满足条件的行，而解决幻读就需要锁住整张表。 Mysql乐观锁： MVCC原理： 不利用锁机制实现的隔离级别，主要实现了在保证数据一致性的前提下，实现了读写的并行。mvcc原理是非每一个数据的更新都有一个版本号。当写事务正在进行时，此时过来一个读事务，读事务会首先生成一个版本号，即该事务想读取哪一个版本的数据。 Mysql悲观锁：先获取锁，再进行业务操作，即“悲观”地认为获取锁是非常有可能失败的，因此要先确保锁获取成功再进行业务操作。 Mysql索引失效 ： （answer）： ​ 索引无法存储null值（索引是有序的，null值进入索引时，无法确定其应该放在哪里。） ​ 不适合键值较少的列 （重复数据太多，索引扫描小消耗也会很大） ​ 模糊查询不能利用索引(like ‘%xx’) ​ 使用条件中有or Mysql事务隔离级别（answer） ​ 读未提交 ​ 不可重复读 ​ 可重复读 ​ 串行化 其中，mysql默认的事务隔离级别是可重复读 MyISAM与InnoDB的区别 ​ MyISAM： 5.3之前的默认表类型。它是存储记录和文件的标准方法。它不是事务安全的，而且不支持外键，它适合于读取大量的select。MyISAM只支持表锁，而不支持行锁，因此在多update、select情况下，并发速度较低。myisam只能管理索引，在索引数据大于分配资源时，会由操作系统来cache ​ InnoDB：5.3之后默认引擎。支持事务的引擎，支持外键、行锁、表锁、事务。如果有大量的update、insert，就适合于innoDB。但是InnoDB查询速度没有MyIsam快。InnoDB不管是数据还是索引，都是自己来管理。InnoDB给mysql提供了具有事务、回滚和崩溃修复能力的事务安全型表。InnoDB提供了行锁，提供了与oracle类型一致的不加锁读取。InnoDB是mysql中第一个提供外键约束的表引擎。InnoDB把表数据和索引放在表空间里，可能包含多个文件，这与其他引擎不一样。需要注意的是：innoDB行级锁的不同索引可能会导致死锁。 ​ 关于主键： ​ Myisam允许没有任何索引和主键的存在，同时myisam的索引都是保存的数据行指向的地址 ​ innodb如果没有主键，就会生成6个字节的主键，同时数据是索引的一部分 ​ 关于count： ​ myisam保存有表的总行数，用select * from table;就会直接取出该值 ​ innodb没有保存表的总行数， 如果使用select count（*） from table；就会遍历整个表，消耗相当大，但是在加了where之后，myisam和innodb的处理方式都一样。 ​ ​ 总结：在写多读少的情况下，使用InnoDB插入性能更稳定。如果对读取速度要求更高，应用还是选择myisam比较好。 数据库水平、垂直拆分： ​ （answer）：目前很多互联网系统都存在单表数据过大的问题，这就降低了查询速度，影响了客户体验。为了提高查询速度，我们可以通过优化sql语句、优化表结构和索引。不过对于那些百万级、千万级的数据库表，即使是优化过后，查询速度还是满足不了需求。这时候我们可以通过分表降低单词查询数据量，从而提高查询速度。一般分表的方式有两种：水平拆分和垂直拆分，二者各有利弊，适用于不同的情况。 ​ 水平拆分：是指数据库表行的拆分。当表的行数超过200万行时，就会变慢，这时可以把一张表的数据拆分成多张表来存放。通常情况下，我们可以采用ID取模的方式把数据分散成若干张表。例如有400w的用户表users，为了提高查询效率我们可以把其分成4张表users1、users2、users3、users4。然后通过id取模的方式把数据分散到四张表内ID%4+1 = [1,2,3,4]。然后查询、更新、删除也是通过取模的方式来操作。 ​ 水平拆分的优点： 表关联基本能够在数据库端全部完成 不会存在某些超大型数据量和高负载的表遇到瓶颈的问题。 应用程序端整体架构改动相对较少。 事务处理相对简单。 只要切分规则就能够定义好，基本上较难遇到拓展性限制 ​ 水平拆分的缺点： 切分规则相对更为复杂，很难抽象出一个能够满足整个数据库的切分规则 后期数据的维护难度有所增加，人为手工定位数据更困难 应用系统各个模块耦合度较高，可能会对后面数据的迁移拆分造成一定的困难 垂直拆分：垂直拆分是数据库列的拆分，把一张列比较多的表拆分为多个表。表的记录并不多，但是字段却很长，表占用空间很大，检索表的时候需要执行大量的IO，严重降低了性能。这时需要把大的字段拆分到另一张表，并且该表与原表是一对一的关系。垂直拆分是指按照业务将表进行分类，分布到不同的数据库上面，这样就将数据的压力分担到不同的库中。 ​ 通常我们按照以下规则进行垂直拆分： 把不常用的字段单独放在一张表 把text、blob等大字段拆分出来放在一张附表中 经常组合查询的列放在一张表中 垂直拆分的优点： 数据库的拆分后业务简单明了，拆分规则明确 应用程序模块清晰明确，整合容易 数据维护方便易行，容易定位 系统之间整合或拓展容易 垂直拆分的缺点： 部分表关联无法在数据库级别完成，需要在程序中完成 对于访问极其繁琐且数据量超大的表仍然存在性能瓶颈，不一定能满足需求 事务处理相对更为复杂 切分达到一定程度之后，拓展性会遇到限制 过度切分可能会带来系统过度复杂而难以维护 数据库范式：（answer） ​ 1NF：关系型数据库中最基本要求。要求记录的属性是原子性，不可分，就是属性不能分。一范式表示数据项不可再分了。 ​ 2NF：在1NF的基础上，不能够有部分依赖。表中的每列都和主键有关 ​ 3NF：在第二范式的基础上再进一层，目标是确保每列都和主键列直接相关，而不是间接相关。即一个关系型满足第二范式，并且除了主键之外的其他列都不依赖于主键列，则满足第三范式。3NF在2NF的基础上，消除了传递依赖 Mysql为什么使用B+树作为索引而不是红黑树作为索引？​ 我们要考虑一个问题：mysql如何衡量查询效率？ ——通过磁盘的IO次数。 ​ B+树只有叶节点存放数据，其余节点用来存放索引，而B树是每个节点都会有data域。为了减少内存的占用，索引也会被存储在磁盘中。B+树除了叶子节点以外 ，其他节点并不存储数据，节点小，磁盘的IO次数就少。 ​ B+树所有的Data域都放在叶子节点中，一般来说会有一个优化，就是将所有的叶子节点用指针串起来，这样遍历叶子节点就能获得所有全部数据，这样就能实现区间访问。 ​ AVL树和红黑树基本上都是存储在内存中才会使用的数据结构。在进行大规模存储的时候，红黑树往往由于树的深度过大而造成磁盘io读写过于频繁。从而导致效率低下。磁盘查找存取的次数往往由树的高度决定。而红黑树的高度比较高。‘ MySQL为什么使用B+树而不用B树作为数据库索引？ B+树的磁盘读写代价更低，B+树的内部节点并没有指向关键值具体信息的指针，因此其内部节点相对B树更小，如果把同一内部节点的关键字存放在同一个盘块中，那么盘块所能容纳的关键字也就更多，一次性读入内存所需要查找的关键字也就更多，相对IO读写次数就降低了。 B+树的查询效率更加稳定，由于非终节点并不是最终指向文件内容的节点，而只是叶子节点中关键字的索引。所以任何关键字的查找必须走一条从根节点到叶节点的路。所有关键字的查询的路径长度相同，导致每一个数据的查询效率相同。 B树在提高了IO效率性能的同时并没有解决元素遍历的低效率问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低。 Mysql表锁​ mysql表锁有两种类型：表共享读锁、表独占写锁。 ​ Mysql行级锁​ InnoDB的行级锁主要分为两种状态：共享锁和排它锁。而在锁定过程中，为了让行级锁和表级锁共存，InnoDB同样使用了意向锁(表级锁定)，也就有了意向共享锁和意向排它锁。意向共享锁可以同时并存多个，但是意向排它锁只能存在一个。所以可以说，InnoDB的锁定模式实际上可以分为四种：共享锁、排它锁、意向共享锁和意向排它锁。 ​ InnoDB行锁是通过给索引上的索引项加锁来实现的。所以，只有通过索引条件来检索数据，innoDB才使用行级锁，否则，INNODB将使用表级锁。 Mysql意向锁​ 意向锁的作用是： ​ *当一个事务需要获取资源的锁定时，如果该资源已经被排它锁占用，则数据库会自动给该事务申请一个该表的意向锁。如果自己需要一个共享锁定，就申请一个意向共享锁。如果需要排它锁定，则申请一个意向排它锁。 * ​ 意向锁是表级行锁。 Mysql悲观锁实现​ 要使用悲观锁，首先必须关闭mysql数据库的自动提交属性，因为mysql默认使用autocommit模式，也就是说，执行一个更新操作后，msyql会立刻将结果进行提交。 ​ 可以通过命令设置mysql为非autocommit模式： ​ set autocommit = 0； ​ 设置完autocommit后，我们就可以执行我们的正常业务了。 ​ 可以通过select语句：select …. for update;这样就实现了悲观锁。需要注意的是，使用select for update会把数据给锁住，不过我们需要注意一些锁的级别，Mysql InnoDB默认Row-level Lock，所以只有明确指定主键，Mysql才会执行Row lock（行锁）；否则Mysql将会执行Table Lock（表锁），把整个表给锁住。 ​ select ……. lock in share mode :表示将共享锁 2、集合源码cas、hashmap、concurrenthashMap、红黑树、AQS、hashtable、CopyOnWriteArrayList, CountdownLatch BlockingQueue 3、数据结构快排、堆排序、希尔排序、归并排序 ​ 直接插入排序： 基本操作是将一个记录插入到已经排序好的有序表中，从而得到一个新的、记录数增1的有序表。 ​ 折半插入排序：在直接插入的基础上，仅仅减少了关键字之间所比较的次数，通过对应索引元素i位置的值，与前i个已排序好的数组的第一个元素和最后一个元素比较直来进行相应的插入。 ​ 希尔排序： 又称为缩小增量排序。希尔排序中，若待排记录序列为正序时，其时间复杂度可为O(n)。 ​ 增量序列可以有各种取法，但需注意：应使增量序列中的值没有除1以外的公因子，并且最后一 个增量值必须为1。 ​ ​ 快速排序：快速排序是对冒泡排序的一种改进。它的基本思想是：通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分关键字小，则可对这两个部分记录继续进行排序，已达到整个序列都有序。 ​ 快速排序的改进：通常采用三者取中的法则来选取枢纽记录，即取数组第一个元素值、中间元素值、和最后元素值的中间值来与第一个元素值对相互替换。通过采用三者取中对的规则可大大改善快速排序在最坏情况下的性能。快排的实现过程如下： ​ ​ ​ 堆排序：堆排序只需要一个记录大小的辅助空间，每个待排序的记录仅占有一个存储空间。 ​ 归并排序：归并的含义是将两个或两个以上的有序表组合成一个新的有序表。归并排序的核心操作是将一维数组中前后相邻的两个有序序列归并为一个有序序列。归并排序是采用分治法的典型应用。 红黑树和平衡二叉树（AVL）的区别​ AVL树是严格的平衡二叉树。平衡条件必须满足（所有节点的左右子树高度差不超过1）。不管我们是执行插入还是删除操作。只要不满足上面的条件，就要通过调整来保持平衡，而这样的调整是非常耗时的，因此，我们可以知道AVL树适合用于插入和删除次数比较少。但是查找多的情况。在应用场景下，如果对插入和删除不频繁，只是对查找要求比较高，那么AVL树还是比较优于红黑树。 ​ 红黑树：红黑树确保没有一条路径会比其他路径长出两倍。因此，红黑树是一种弱平衡二叉树（由于是弱平衡，可以看到，在相同节点的情况下，AVL树的高度低于红黑树），相对于要求严格的AVL树来说，所以对于搜索、插入、删除操作较多的情况下，我们就用红黑树。 ​ ​ B和B+树 二叉树和二叉平衡树 ​ B和B+树 ：answer： B树能够存储数据，对其排序并允许时间复杂度为logn来进行查找、排序、插入和删除的数据结构。B树为系统最优化大块数据的读和写。B树算法减少定位记录所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。 ​ 对于M阶B树，每层每个块最多只能有M-1个元素，同时一个块最多只能有M个分支。 ​ B+树是对B树的一种变形树，它与B树的差异在于： 有k个子节点的节点必然有k个关键码 非叶节点仅仅只有索引作用，跟记录相关的信息存放在叶节点中。 树的所有叶节点构成一个有序列表，可以按照关键码排序的次序遍历全部记录。 B树和B+树的区别是：B+树的非叶节点只包含导航信息，而不包含实际的值，所有的叶子节点和相连的节点使用链表来进行相连，便于区间查找和遍历。 但是B树也有其优点：B树的每个节点都包含了key和Value，因此经常访问的元素可能离根节点更近，因此访问速度也更快。 4、jvm类加载机制、jvm运行时数据区、java内存模型、jvm分区 GC算法、minor GC 和full GC jvm参数 CMS、G1（回收过程以及机制） 字节码 jvm调优 栈帧（虚拟机进行方法调用和方法执行的数据结构，虚拟机运行时数据区的虚拟机栈） 内存泄漏与内存溢出及其原因 内存泄漏：分配出去的内存却无法回收 内存溢出：程序要求的内存超出了所能分配的最大内存 jvm常见命令Xmx:最大堆容量 Xms:初始堆容量 Xmn:新生代容量 Xss:栈容量（栈帧大小） -XX:+HeapDumpOnOutOfMemoryError可以让虚拟机出现OOM时Dump出当前的内存转储快照以便于事后分析 -XX:MaxPermSize:最大方法区容量 -XX:PermSize:方法区大小 -XX:SurvivorRatio =8:Eden和Survivor的空间比例是8:1 jvm运行时数据区域​ jvm运行时数据区域包括：方法区（线程共享）、虚拟机栈（线程私有）、本地方法栈（线程私有） ​ 堆（线程共享）以及程序计数器（线程私有） ​ 线程计数器：是对应线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是改变这个计数器的值来选取下一条需要执行的字节码指令。 ​ java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现多线程的执行的。因此在任何一个时刻，一个处理器核（多核处理器的一个核）都只会执行一个线程中的指令。因此，为了线程切换后，快速定位当前线程上一次执行的位置，就需要通过线程计数器来指定标记。 ​ ​ 虚拟机栈：生命周期与线程相同。虚拟机栈描述的是java方法执行的内存模型。栈中包含了各种方法运行时所需要的信息。每个方法在运行时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等。如果线程请求的栈深度超过最大虚拟机的允许深度，会抛出StackOverFlowException。如果方法请求的栈深度无法申请到足够的内存，就会抛出OOM。 ​ ​ 本地方法栈：与虚拟机栈发挥的作用相似，它们之间的区别不过是虚拟机栈是为虚拟机执行java字节码服务的；而本地方法栈是为native本地方法来服务的。 ​ ​ java堆：java虚拟机管理的最大一块内存。堆中管理了所有java对象实例，几乎所有的对象都在这里分配内存。java堆是GC的主要区域。现代收集器基本采用分代收集算法，所以java堆还可以分为新生代和老年代。进一步的划分是为了更好地回收内存，或者更快地回收内存。可以通过-Xmx和-Xms命令来设置堆的最大和初始堆内存。如果分配时，堆中没有内存可以再进行分配，会抛出OOM。 ​ 方法区：用于存储已经被jvm加载过后的各种class的类信息、常量、静态变量等数据。 ​ 运行时常量池（HotSpot中的永久代）：是属于方法区的一部分。class文件除了有类的部分信息以外，还有一项信息是常量池，用于存放编译器生成的各种字面量和符号引用。这部分内容将在类加载后进入方法区的运行时常量池中存放。需要注意的是：程序在运行时，可也将常量放入到常量池中。当常量池的容量超出限制时，会抛出OOM。 ​ 在HotSpot虚拟机中，对象在内存中存储的布局可以分为3个区域：对象头（Header）、实例数据(Instance Data)以及对齐补充(padding)。 ​ 虚拟机的对象头（MarkWord）包含两部分信息：哈希码(25bit)、GC分代年龄标志(4bit)、锁状态标志(2bit)、线程持有的锁、偏向线程ID、偏向时间戳等。 对象的创建过程​ 检查常量池中是否有即将要创建的这个对象所属的类的符号引用； 若常量池中没有这个类的符号引用，说明这个类还没有被定义！抛出ClassNotFoundException；若常量池中有这个类的符号引用，则进行下一步工作；进而检查这个符号引用所代表的类是否已经被JVM加载； 若该类还没有被加载，就找该类的class文件，并加载进方法区；若该类已经被JVM加载，则准备为对象分配内存； 根据方法区中该类的信息确定该类所需的内存大小； 一个对象所需的内存大小是在这个对象所属类被定义完就能确定的！且一个类所生产的所有对象的内存大小是一样的！JVM在一个类被加载进方法区的时候就知道该类生产的每一个对象所需要的内存大小。 从堆中划分一块对应大小的内存空间给新的对象；分配堆中内存有两种方式： 指针碰撞如果JVM的垃圾收集器采用复制算法或标记-整理算法，那么堆中空闲内存是完整的区域，并且空闲内存和已使用内存之间由一个指针标记。那么当为一个对象分配内存时，只需移动指针即可。因此，这种在完整空闲区域上通过移动指针来分配内存的方式就叫做“指针碰撞”。空闲列表如果JVM的垃圾收集器采用标记-清除算法，那么堆中空闲区域和已使用区域交错，因此需要用一张“空闲列表”来记录堆中哪些区域是空闲区域，从而在创建对象的时候根据这张“空闲列表”找到空闲区域，并分配内存。综上所述：JVM究竟采用哪种内存分配方法，取决于它使用了何种垃圾收集器。为对象中的成员变量赋上初始值(默认初始化)； 设置对象头中的信息； 调用对象的构造函数进行初始化 对象的内存模型​ 对象在内存中分为三部分： 对象头 实例数据 对齐补充 垃圾收集器与内存分配策略 常见的对象判断可回收算法​ 可达性分析算法：GC ROOTS引用链。从GC ROOTS的的对象开始查看对应的引用对象，一直遍历下去，如果对象被引用到，则表示该对象不需要进行GC 。若存在对象，使得GC ROOT引用不到，则表示该对象需要被回收。在java语言中，可以作为GC ROOT的对象包括：虚拟机栈中引用的对象、类静态属性引用的对象、方法区中引用的对象、本地方法栈中的JNI引用的对象。 ​ 无用的类的回收​ 类需要满足三个条件才能被回收： 该类的所有实例都已被回收 记载该类的ClassLoader已被回收 该类对应的Class对象没有任何地方被引用。无法在任何地方通过反射来访问该类的方法。 垃圾回收算法标记清除算法（新生代算法）分为标记和清除两个过程，标记完成后统一回收所有需要被回收的对象 标记清除的缺点： 产生内存碎片较多，导致内存利用率不高 标记和扫描过程效率不高 复制算法（新生代算法）将堆新生代内存分为两块。一半用于存储对象内存，然后将不需要的内存放入另一半中，最后将这一半内存全部清空，使得每次只对一个半区进行回收。现代商业算法都是采用此方案，不过不是划分一半，而是分为Eden和survivor区，一般而言Eden和Survivor的比例是8:1。 复制算法优点： 算法简单，比较容易实现 不会产生内存碎片 内存都是连续分配的 复制算法缺点： 内存空间利用率较小，每次只有一半空间能使用 将不需要gc的对象复制到令一半区，性能耗费较大 标记-整理算法(老年代算法)标记过程与标记-清除一样，只是标记之后不再清除。而是将剩余的存活对象内存相互整理，清除内存碎片，提高内存空间利用率。 垃圾回收器​ 垃圾回收算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。 Serial回收器(新生代回收器)​ 单线程回收器。是指它在工作时，必须暂停所有工作进程，直到它收集结束(Stop the World)。 Serial收集器新生代采用标记-清除算法。老年代采用标记-整理算法。 Parnew收集器(新生代)​ Serial收集器的多线程版本，除了使用多线程进行垃圾回收之外，其余行为与Serial一致，包括Stop the World。新生代采用标记-清除算法，老年代采用标记-整理算法。Parnew是许多运行在Server模式下虚拟机的首选。Serial和Parnew都能与CMS进行配合。 Parallel Scavenge(新生代收集器)采用复制算法实现的新生代收集器，而且是并行的的多线程收集器。 其目的是达到一个可控制的吞吐量。停顿时间越短则越适合执行与用户进行交互的程序。 Serial Old（老年代收集器）以标记-整理作为实现原理，同样是一个单线程收集器，需要Stop the World。 Parallel Old(老年代收集器)Parallel Scavenge收集器的老年代版本，使用多线程和标记-整理算法。同样注重吞吐量优先。 CMS收集器(老年代收集器)Concurrent Mark Sweep。采用标记-整理算法，它是以获取最短停顿时间为目标的收集器。 CMS的执行过程如下： 初始标记（Stop the world）：标记GC Root能够直接关联的对象，速度很快 并发标记： GC ROOT tracing。时间较长。可以和用户线程并行执行，标记所有可达对象 重新标记（Stop the World）：为了修正并发期间因为用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。停顿时间比初始标记稍长。对并发标记阶段用户线程运行所产生的垃圾对象进行标记修正。 并发清除：时间较长。可以和用户线程并行执行，清理垃圾。采用标记清除算法 由于整个过程耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作。所以，从总体上讲，CMS收集器的回收过程是与用户进程一起并发执行的。 CMS优缺点 ​ 优点：并发，低停顿 ​ 缺点： G1收集器面向服务端应用的垃圾回收器。 G1收集器的运作步骤大致如下： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序据需运作而导致标记产生变动的那一部分标记记录。 筛选标记 G1的优点如下： 并行与并发 分代收集 空间整合 可预测的停顿 大对象直接进入老年代​ 所谓的大对象是指，需要大量的连续内存空间的java对象，最典型的大对象就是那种很长的字符串以及数组。大对象对虚拟机的内存分配来说就是一个坏消息。可以将比较大的对象之间存储到老年代中，以避免新生代Eden和Survivor之间的大对象复制带来的性能消耗。 长期存活的对象进入老年代​ 虚拟机给每个对象定义了一个对象年龄计数器。如果对象在Eden出生并经过一次Minor GC之后仍然存活，并且能够被Survivor容纳的话，就会被移动到Survivor空间中，并且对象年龄设为1。当对象的年龄增加到一定程度之后，就会直接晋升到老年代。 Sun JDK监控和故障处理工具jps：所有HotSpot虚拟机进程 jstats: 用于收集HotSpot虚拟机各个方面的运行数据 jinfo:虚拟机配置信息 jmap:生成虚拟机的内存转储快照(heapdump) jhat:分析heapdump文件，它会建立一个http服务器，让用户在浏览器上查看分析结果 jstack：显示虚拟机的线程快照 java虚拟机类加载机制类的加载：虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析的初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 ​ 类被加载的时机：加载、验证、准备、解析、初始化、使用、卸载。 ​ 类的加载过程： 通过一个类的全限定名来获取定义此类的二进制字节流 将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口 ​ 验证： 文件格式验证(是否已魔数开头) 元数据验证 字节码验证 准备：为类变量分配内存并设置初始化值 解析：虚拟机将常量池内的符号引用替换为直接引用的过程。 初始化：执行类构造器的方法 对于任何一个类，都需要由加载它的类加载器和这个类本身一同确立在java虚拟机中的唯一性。 双亲委派模型从java虚拟机角度上讲，只存在两种不同的类加载器：一种是启动类加载器(Bootstrap ClassLoader),这个类加载器使用C++实现。另一部分是所有的加载器，都由java实现，并且全部继承自抽象类ClassLoader。 ​ BootstrapClassLoader:负责将存放在JAVA_HOME\\lib目录类的库。该类无法被java程序直接引用 ​ ExtensionClassLoader:拓展类加载器，加载JAVA_HOME\\lib\\ext下的库 ​ ApplicationClassLoader:系统类加载器，加载Classpath上指定的类库，开发者可以直接使用这个类加载器 类加载器之间的的层次关系：称为双亲委派模型。双亲委派模型要求：处理底层的启动类加载器以外，其余的类加载器都应有自己的父类加载器。这里的父子关系不会以继承来实现，而是以组合模式来实现。 ​ 双亲委派模型流程是：每层的类加载器，都会把类加载的请求转发给父加载器去处理，最后传送到顶层的启动类加载器，只有父加载器无法实现加载时，子加载器才会自己尝试加载。这样的好处是：无论哪个类要加载一个类，都会最终委派个处于模型最顶端的启动类加载器去加载，保证了Object类在程序中的各个类加载器环境都是一个类。 Java语法糖泛型与类型擦除​ 泛型的本质是参数化类型应用，也就是说所操作的数据类型被指定为一个参数，这种参数类型可以用在类、借口和方法中的创建中，分被称为泛型类、泛型接口、和泛型方法。 ​ 对于运行期的java来说，ArrayList和ArrayList是同一个类，泛型技术实际上是java的一个语法糖，java语言的泛型方法实现称为类型擦除。java代码被编译为class字节码文件后，泛型都会被擦除。 ​ 方法重载要求方法具备不同的特征签名，返回值并不在方法的签名之中，所以返回值不参与重载选择，但是在class文件中，只要描述符（包括返回类型）不是完全一致的两个方法就可以共存。 Java内存模型硬件的效率与一致性​ 处理器要与内存交互，比如读取数据、存储计算结果等，这个IO操作是很难消除的。由于计算机的存储设备与处理器的运算速度存在几个量级的差距，所以不得不在运算器和存储设备之间加入一个高速缓存（Cache），使得所需要的数据存入到高速缓存中，运算结束后，再通过高速缓存写回到存储设备中。加入了高速缓冲的后果就是：带来了一个问题：缓存一致性。每个处理器都有自己的高速缓存，而它们最后都要写会同一个主存。 java内存模型​ java内存模型定义了所有的变量都存储在主存中，同时每个线程还有自己的工作内存，不同的内存无法访问对方的工作内存，只能通过主存的内容来进行通信。 ​ 从变量、主内存、工作内存的定义来看，主内存主要对应于java堆中的对象实例数据部分，而工作内存则对应于虚拟机栈的部分区域。主内存就直接对应于物理硬件的内存，而为了获得更好地运行速度，虚拟机可能会让工作内存优先存储于寄存器和高速缓存之间。 ​ volatile可以说是java虚拟机提供的最轻量级的同步机制。volatile保证了两种机制： 保证了内存可见性（对一个volatile变量的写操作先行发生于后面变量对这个变量的读操作） 禁止指令重排序（保证了变量赋值的操作顺序与程序代码的执行顺序一致） 为什么volatile关键字能保证共享变量的内存可见性?​ volatile修饰了一个成员变量后，这个变量的读写就会比普通变量多一些步骤。 volatile变量写：当被volatile修饰了的变量进行读后，并不会写入到本地线程变量中，而是直接写到主存中。 volatile变量读：被volatile修饰了的变量被线程读时，线程不是从本地变量中读，而是在主存中去读。 指令重排序​ 重排序是指编译器、处理器在不改变程序执行结果的前提下，重新排列指令的执行顺序，来达到最佳的运行效率。重排序可分为编译器重排序和处理器重排序。 ​ 可见性：volatile、synchronized、final 先行发生原则判断数据是否存在竞争、线程是否安全的主要依据。如果操作A先行发生操作于B，就是指发生操作B之前，操作A的影响能被B察觉到。 JVM锁消除​ 锁消除是指虚拟机即时编译器在运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。如果在一段代码中，堆上的所有数据都不会逃逸出去从而被其它线程访问到，那就可以把它们当做栈上的数据来处理，认为它们是线程私有的，同步加锁也就无需存在。 java线程的几种状态： 新建 运行 等待 阻塞 结束 Synchronized关键字​ synchronized经过编译之后，会在同步块的前后分别形成monitorenter和monitorexit两个字节码指令，这两个字节码都需要一个reference明确指定要加锁和解锁的对象。 ​ 执行monitorenter时，首先要获取对象的锁，如果这个对象还没被锁定，或者当前线程已经拥有了那个对象的锁，就把锁的计数器+1；相应的，执行monitorexit会把锁的计数器减1。当锁计数器为0时，锁就被释放了。 5、springioc、aop、di。 IOC的实现、bean的注册过程(applicationContext -&gt; beanDefinition -&gt; listableBeanFactory -&gt; 单例实例化) Spring IOC​ IOC(Inversion Of Control) 是指容器控制对象之间的关系，而不是传统实现中，有程序代码来直接控制。控制权由应用代码转到了外部容器，控制权的转移是所谓翻转。对于spring而言，就是由spring来控制对象的生命周期和对象之间的关系；IOC还有另外一个名字–(DI, Dependency Injectino ,依赖注入)。所谓依赖注入，即组件之间的依赖关系由容器在运行期间决定，即由容器动态地将某种依赖关系注入到组件中。 ​ 在spring的工作方式中，所有的类都会在spring容器中登记，告诉spring这是一个什么东西，然后spring会在系统运行到适当的时候，会把所需要的东西主动提供。所有用户自定义类的创建、初始化、销毁都由spring来控制，也就是说控制对象生存周期的不再是它所引用的对象，而是spring。对于某个具体的实现而言，以前是它控制其他对象，现在是所有对象都被spring控制，所以这叫控制反转。 ​ DI（依赖注入）的思想是通过反射机制来实现的，在实例化一个类的时候，它通过调用类中set方法将事先保存在hashMap中的类属性来注入到类中。总而言之，在传统的对象创建过程中，通常由调用者来创建被调用者的实例，而spring中创建被调用者的工作则由spirng来完成，然后注入调用者，即所谓的依赖注入or控制反转。注入方式有两种：依赖注入和设置注入；ioc的优点是：降低了组件之间的耦合，降低了业务对象之间替换的复杂性，使之能够灵活的管理对象。 Spring AOP ​ 面向对象编程有些弊端，当需要为多个不具有继承关系的对象引入同一个公共行为时，例如日志、安全检测等，我们只有在每个对象中引入公共行为，这样程序中就产生了大量的重复代码，程序就不方便维护了，所以就有了对面向对象的补充，即面向切面编程(AOP),AOP所关注的方向是横向的，不同于OOP的纵向。 AOP面向切面编程，是对OOP的有益补充 AOP利用一种被称为横切的技术，剖解开封装的对象内部，并将那些影响了多个类之间的公共行为封装到一个可重用模块，并将其声明为“Aspect”。所谓切面，就是将那些与业务无关，却将业务模块所共同调用的逻辑或责任封装起来，比如日志记录，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 AOP就是代表的一个横切的关系，讲对象比作为一个空心的圆柱体，其中封装了对象的属性和行为；而面向切面编程的方法，就是将这些圆柱体以切面的方式剖析开，选择性地提供业务逻辑。而剖开的切面，就是所谓的“方面”了。 实现AOP的技术：主要分为两大类：一是采用动态代理的技术，利用截取消息的方式，对该消息进行修饰，用于取代原有对象的执行；二是采用静态织入的方式，引用特定的语法创建切面，从而使得编译器可以在编译期间织入相关切面的代码。 Spring实现AOP:JDK动态代理和CGLIB动态代理：代理对象必须是某个接口的实现，它是通过在运行期间创建一个接口的实现类来完成对目标对象的代理；其核心是两个类：InvocationHandler和Proxy。CGLIB代理：实现原理类似于JDK动态代理，只是它在运行期间生成的代理对象是针对目标类拓展的子类。CGLIB是高效的代码生成包，底层是依靠ASM（java字节码编辑类库）操作字节码来实现的，性能比JDK强。使用ASpect注入切面和@AspectJ注解驱动的切面实际上底层也是通过动态代理来实现的。 ​ 一个类被AOP织入Advice，就会产生一个结果类，它是融合了原类和增强逻辑的代理类。 ​ 在spring AOP中，一个AOP代理是一个JDK动态代理对象或CGLIB代理对象。 ​ ​ 在Spring AOP中，join point总是方法的执行点，即只有方法连接点。 ​ advice是在join point 上执行的，而point cut规定了哪些join point可以执行哪些advice 织入(wearing)​ 将aspect和其他对象连接起来，并创建adviced object的过程 ​ 根据不同的实现技术，AOP有三种织入技术： 编译器织入，这要求有特殊的java编辑器 类加载器织入，这需要有特殊的特殊的类加载器 动态代理技术，在运行期间为目标类添加增强(Advice)生成子类的方式。Spring采用动态代理织入，而AspectJ采用编译器织入和类加载期间织入。 ​ JDK动态代理只能对实现了接口的类生代理，而不能针对类 ​ CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法，因为是继承，所以该类或方法最好不要声明成final。 ​ ​ Spring中的IOC加载过程​ IOC容器的初始化是由refresh方法来启动的，这个方法标志着IOC容器的正式启动。 ​ 具体来说这个启动过程包括三个启动过程： BeanDefinition的Resource定位 BeanDefinition的载入与定位 BeanDefinition在IOC容器中的注册 ​ Resource定位：我们一般使用外部资源来描述Bean对象，所以IOC容器第一步就是需要定位Resource外部资源。Resource的定位就是BeanDefinition的资源定位，它是由ResourceLoader通过统一的Resource接口来完成的，这个Resurce对各种形式的BeanDefinition都是用了统一的接口。 ​ ​ BeanDefinition的载入： ​ BeanDefinitionReader读取、解析Resource定位的资源，也就是将用户定义好的Bean表示成IOC容器的内部数据结构也就是BeanDefinition。在IOC容器内部维护着一个BeanDefinition Map的数据结构，通过这样的数据结构，IOC容器能够对Bean进行更好的管理。在配置文件中每一个都对应一个BeanDefinition对象。 ​ ​ BeanDefinition的注册： ​ 在IOC容器中注册这些BeanDefinition,这个过程是通过BeanDefinitionRegistry接口来实现的。在IOC容器内部其实是将第二部解析过程得到的BeanDefinition注册到HashMap中，IOC容器就是通过这个HashMap来维护这些BeanDefinition的。需要注意的是，这个过程并没有完成依赖注入，依赖注册在应用第一次调用getBean向容器所要bean时候。当然我们可以通过设置预处理，即对某个bean设置lazyinit属性，那么这个bean的依赖注入就会在容器初始化的时候完成。 ​ Spring中bean的加载 转换对应的beanName（去除factorybean的修饰符） 尝试从缓存中加载单例（创建单例的时候会存在依赖注入的情况，而在创建的时候为了避免循环依赖，在spring中创建bean的原则是不等bean创建完成就会将创建bean的objectFactory提早曝光到缓存中） bean的实例化 原型模式的依赖检查 检测parentBeanFactory 寻找依赖 针对不同的scope进行创建 类型装换 在默认情况下，spring通过反射机制利用bean的class属性来指定实现类来实现实例化bean。 Spring中的生命周期 实例化一个bean，也就是通常的一个new 按照spring上下文对实例化的bean进行配置，也就是IOC注入 如果这个bean实现了BeanNameAware接口，则调用这个setBeanName方法，此处传递的是spring配置文件中bean的ID 如果这个bean实现了BeanFactoryAware接口，会调用它实现的setBeanFactory(),传递的是spring工厂本身 如果这个bean实现了ApplicationContextAware接口，会调用setApplicationContext方法，传入spring上下文 如果这个bean关联了BeanPostProcessor接口，将会调用postProcessorBeforeInitialization方法，BeanPostProcessor经常被用作是bean内容的更改，并且由于这个是在bean初始化结束时调用after方法，也可用于内存或者缓存。 调用bean定义文件中定义的init-method 执行BeanPostProcessor的postAfterInitialization 如果实现了Disposable接口，则调用这个destroy方法 Spring中的BeanFactory和FactoryBean​ BeanFactory是IOC最基本的容器，负责生产和管理bean，它为其他具体的IOC容器提供了最基本的规范，例如DefaultListableBeanFactory。它是创建bean的父接口。 ​ FactoryBean是一个接口,当在IOC容器中的Bean实现了FactoryBean之后，通过getBean(String beanName)获取到的Bean对象并不是FactoryBean的实现类对象，而是这个实现类中的getObject方法返回的对象。想要获取FactoryBean的实现类，就要getBean(&amp;beanName),在beanName之前加上&amp; ​ FactoryBean和BeanFactory其实没有什么可比较性的，只是两者的名称特别接近，所以有时候会拿出来比较一番，BeanFactory提供了IOC最基本的形式，给具体的IOC容器的实现提供了规范，FactoryBean可以说为容器中bean的实现提供了更加灵活的方式，FactoryBean在IOC容器的基础之上加上了一层简单工厂模式和装饰模式，我们可以在getObject（）方法中灵活配置。 @Autowired和@Resource的区别​ @Autowired属于spring的注解，@Resource属于JSR-250的规范注解。@Resource的作用相当于 @Autowired，只不过@Autowired是按照byType来自动注入，而@Resource是默认按照byName来实现注入的。 @Autowired默认按照类型装配，默认情况下必须要求依赖对象必须存在。如果要运行null值，可以设置它的required属性为false，如果想要使用名称来装配就可以结合@Qualifier注解进行使用。 Spring MVC的处理流程 用户向服务器发送请求，请求被spring前端控制Servlet DispatcherServlet捕获 DispatcherServlet对请求的URL进行解析，得到请求资源标识符（URI）。然后根据这个URI，调用HandleMapping获得该handler配置的所有相关的对象（包括handler对象以及handler对象对应的拦截器），最后以HandlerExecutionChain对象的格式返回。 DispatcherServlet根据获得的Handler,选择一个合适的HandlerAdapter。（如果成功获得HandlerAdapter后，此时将开始执行拦截器的preHandler方法）。 提取Request中的数据模型，填充Handler入参，开始执行Handler(Controller)。在填充Handler入参的过程中，根据对应的配置，Spring将进行一些额外的工作。 ​ HttpMessageConveter:将请求消息（json，xml）等转换成一个对象，将对象转换为指定的相应信息 ​ 数据格式化：对请求消息进行数据格式化，比如将字符串转换成格式化数字或格式化日期等。 ​ 数据验证：验证数据的有效性（长度、格式等），验证结果存储到BidingResult或Error中。 Handler执行完成过后，向DispatcherServlet返回一个ModelAndView对象，选择一个合适的ViewResolver对象来返回给DispatcherServlet。 将ViewResolver结合Model和View。来渲染视图。 将渲染结果返回给前端 为什么SpringMVC只使用一个Servlet（DispatcherServlet）来处理所有请求？ ​ 为什么SpringMVC要结合使用HandlerMapping以及HandlerAdapter来处理Handler？ 因为符合面向对象中的单一职责原则，代码架构清晰，便于维护，最重要的代码可重用性高。比如HandlerAdapter可能会被用于处理多个Handler。 6、Redisredis几种数据结构 应用场景 zset、LRU、FIFO、异步消息队列、计数器、分布式锁 为何单线程速度快 集群 持久化：AOF和RDB 什么是Redis​ Redis全称是 remote Dictionary Server。 ​ Redis本质上是一个key-value类型的内存数据库，很像memCached,整个数据库统统加载在内存中进行操作，定期通过异步操作把数据库数据flush到硬盘中进行保存。 ​ 因为是纯内存操作，Redis性能非常出色，每秒可以处理10万次读写操作，是性能最快的Key-Value键值对数据库。 Redis与Memcached相比的优势​ Memcached所有的值均是简单的字符串，redis作为其代替者，支持更加丰富的数据类型。 ​ Redis的速度比Memcached快很多 ​ redis可以持久化其数据 Redis支持哪几种数据类型​ String (字符串) 。一个字符串类型的值最大能存储量为512M ​ List （列表） ​ Set （集合） ​ Sorted Set（zset，有序集合） ​ Hash （哈希表） Redis的数据淘汰策略​ LRU（最近最少使用）： 尝试回收最近最少使用的键，使得新添加的数据有空间存放。 ​ TTL（Time To Live）: 优先回收存活时间比较短的键，使得新添加的数据有空间存放。 Redis事务​ 在非关系型数据库中，我们都知道有事务存在，所谓的事务就是应用程序中有一系列严密的操作，所有操作必须成功完成，否则在每个操作中所有的更改都会被撤销，也就是事务具有原子性，一个事务的一系列操作要么全部成功，要么全部失败。这就是事务的四大特性，也就是常说的ACID。 ​ Redis事务：可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按照顺序串行化执行而不会被其他命令插入，不许加塞。 ​ Redis事务命令： ​ multi：标记一个事务块的开始 ​ exec：执行所有事务块的命令 ​ discard：放弃本次事务的执行，回滚 ​ watch：监视一个或者多个key，如果在事务执行之前这些key被其他命令所改动，那么事务会被打断。 ​ Redis事务三大特性： 单独的隔离操作：事务中的所有命令都会序列化、按照顺序执行。事务在执行的过程中，不会被其他客户端发送来的命令所打断。 没有隔离级别的概念：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行，也就不会存在事物内的查询要看到事务里面的更新，在事务外查询不能看到这个让人十分头痛的问题。 不保证原子性：redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。 Redis服务器初始化启动过程 初始化服务器全局状态 载入配置文件 创建daemon进程 初始化服务器功能模块 载入数据 开始事件循环 Redis缓存穿透​ 查询一个数据库中一定不存在的数据。正常的使用缓存流程大致是：数据缓存先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放入到缓存中。如果数据库查询对象为空，则不放入缓存。 ​ Redis集群方案应该怎么做？都有哪些方案？ codis 。目前用的最多的集群方案。 redis cluster。原理是其原理不是一致性hash，而是hash槽 Redis集群原理​ ​ Redis Cluster的原理：cluster是一个集群管理的插件，当我们存取的key到达的时候，redis会根据crc16的算法得出一个结果，然后把结果对16384求余数，这样每个key都会对应一个编号在0-16383之间的哈希槽，通过这个值，去找到对应的插槽所对应的节点，然后直接跳转到这个对应的节点进行存取操作。 Redis哈希槽： Redis集群中有16384个哈希槽，每个key通过CRC16检验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分槽。​ Redis集群时，是有好多个redis一起工作的，那么，就需要这个集群不那么容易挂掉，所以理论上就应该给集群中的每个节点备份至少一个的redis服务。这个备份的redis称为节点(slave)。每一个节点都存有主节点以及从节点的信息。Redis节点的复制策略是异步复制。 ​ 它们之间通过互相的ping-pong判断是否这个节点可以连接上。如果有一半以上的节点去ping一个节点没有回应时，集群就认为这个节点宕机了，然后取连接它的备用节点。如果某个节点和所有从节点全部挂掉，我们集群就进入fail状态。如果一半以上的主节点宕机，我们集群同样也进入了fail状态。 Redis的投票机制​ redis投票机制是集群中所有master参与，且当前master没有slave，集群进入fail状态，也可以理解成集群的slot映射不完整进入fail状态。 ​ 如果集群中超过半数的master挂掉，无论是否有slave，集群·就进入了fail状态。 Redis的主从复制模型​ 为了使部分节点失败或者大部分节点节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品。Redis支持主从的模式。原则是：master会将数据同步到slave，而slave不会将数据同步到master。slave启动时会连接master来同步数据。 ​ 这是一个典型的分布式读写分离模型。我们可以利用master来插入数据，slave来提供检索服务。这样可以有效减少单个机器并发访问控制数量。 Redis集群数据如何保证一致性？​ 是通过redis的主从复制来实现多个数据库之间的数据同步。master可以进行读和写，当发生写操作的时候，会自动将数据同步到slave数据库。 Mysql里有2000w数据，redis中只存20w数据，如何保证redis中的数据都是热点数据​ answer：当redis中内存数据集上升到一定大小时候，就会进行数据淘汰策略。redis提供了6种数据淘汰策略： ​ voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 ​ volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 ​ volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 ​ allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 ​ allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 ​ no-enviction（驱逐）：禁止驱逐数据 Redis的RDB和AOFRDB(Redis DataBase)： RDB是Redis默认的持久化方案，在指定的时间间隔内，执行指定次数的写操作，会将内存中的数据写到磁盘中，即在磁盘中指定目录下生成一个dump.rdb文件。Redis重启会通过加载dump.rdb文件恢复数据。 ​ RDB的优缺点 ​ 优点： 适合大规模的数据恢复 如果业务对数据完整性和一致性要求不高，RDB是很好的选择 ​ 缺点： 数据的一致性和完整性不高，因为RDB可能在最后一次备份时宕机了。 备份时占用内存，因为Redis在备份时会独立创建一个子进程，将数据写到一个临时文件，最后再将临时文件，最后再将临时文件替换之前的备份文件。 AOF（Append Only File） ​ Redis默认不开启。它的出现是为了弥补RDB的不足（数据不一致），所以它采用日志的形式来记录每个写操作，并追加到文件中。Redis重启会根据日志文件内容将写指令从前到后执行一次以完成数据的恢复工作。 ​ 正常情况下，将appendonly.aof文件拷贝到redis的安装目录中，重启redis服务即可。但在实际开发中，可能因为某些原因导致appendonly.aof文件格式异常，从而导致数据还原失败，可以通过命令redis-check-aof进行修复。 Redis几种数据结构的底层实现​ 字符串​ Redis没有采用C语言传统的字符串表示，而是自己构建了一种名为简单动态字符串(Simple Dynamic String , SDS)的抽象类型，并将SDS作为Redis的默认字符串表示。 ​ 列表​ 链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。 ​ Redis的列表底层实现就是通过链表来实现的。列表数据结构如下： ​ 哈希​ Redis字典所使用的哈希表由如下结构体表示： ​ 在结构体中存有指向dictEntry数组的指针，而我们用来存储数据的空间就是dictEntry。dictEntry的数据结构如下： ​ 在数据结构中，我们清楚key是唯一的，但是我们存入到里面中的key并不是直接的字符串，而是一个hash值，通过hash算法，将字符串转换成对应的hash值，然后在dictEntry中找到对应的位置。如果出现hash冲突，redis采用了链地址法来解决hash冲突。 ​ 随着对hash表的不断操作，hash表中保存的键值对会逐渐发生变化，为了让hash表的负载因子维持在一个合理的范围之内，我们需要对hash表的大小进行相应的拓展或者压缩，这时候，可以通过rehash操作来完成。 有序集合​ 有序集合的实现：通过跳表来实现排序的，用map来快速定位一个节点。 ​ 跳跃表(skiplist) 是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表是一种随机化的数据，跳跃表以有序的方式在层次化的链表中保存元素，效率可以和平衡树媲美。查找、删除、添加等操作都可以在对数期望时间下完成，并且比起平衡树来说，跳跃表的实现要简单直观很多。 ​ 与红黑树等平衡树相比，跳表的优点： 插入速度非常快速，因为不需要进行旋转操作来维护平衡性 更容易实现 支持无锁实现 Redis只在两个地方使用了跳跃表，一个是有序集合，另一个是在集群节点中用作内部数据结构。zkskiplistnode节点的数据结构如下： 跳表(zskiplist)中包含zkskiplistnode的头结点和尾节点。 ​ Redis的集合实现过程​ Redis单进程单线程​ redis采用队列技术量并发访问变为串行访问，消除了传统数据库串行控制的开销。 7、并发synchronized的锁膨胀、CAS、volatile、ReentrantLock和Synchronized的区别 Synchronized底层(mutex标志位) 自旋锁 独占锁、共享锁 线程池、Condition CopyOnWriteList CountdownLatch、Semaphore CyclicBarrier Semaphore Synchronized VS Lock 在AQS中维护着一个FIFO的同步队列，当线程获取同步状态失败以后，则会加入到这个CLH同步队列的队尾并一直保持自旋。在CLH同步队列中的线程在自旋时会判断其前驱节点是否为首节点，如果为首节点则不断尝试获取同步状态，获取成功后则退出CLH同步队列。当线程执行逻辑完毕后，会释放同步状态，释放后会唤醒其后继结点。 ​ 8、网络TCP三次握手、四次挥手 HTTP1和HTTP1.1、HTTP2.0区别 TCP和UDP协议的区别于各自场景 Cookie和Session OSI七层模型 TCP/IP模型 syn和SYN的区别 ​ （SYN表示TCP三次握手中请求连接的标识符，SYN为1且ACK为0，代表客户端请求连接，SYN为1且ACK为1，表示服务器同意连接， ack=x+1表示服务端希望下一个数据报发送序号从x+1开始的字节。 ） ​ FIN为1表示报文段是一个连接释放请求，seq=u,u-1是A向B发送的最后一个字节的序号。 ​ 四次挥手时，client为什么TIME_WAIT状态还需要等待2msl后才能返回到closed状态？ HTTP工作原理​ HTTP采用了请求/响应的模型，客户端向服务器发送一个请求报文，请求报文中包含请求的方法，URL、协议版本、请求头和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。 ​ 以下是HTTP请求/响应的步骤： 客户端连接到web服务器： 一个HTTP客户端，通常是浏览器，与WEB服务器的HTTP端口（默认为80）建立一个TCP套接字连接 发送HTTP请求 通过TCP套接字，客户端向web服务器发送一个文本的请求报文，一个请求报文由请求行、请求数据等组成 服务器接收响应并返回HTTP响应 web服务器解析请求，定位请求资源。服务器将资源复写到TCP套接字，由客户端来进行读取。一个响应由状态行、响应头部、空行和响应数据组成。 释放TCP连接 若Connection为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接；若connection模式为keep-alive,则保持该连接，在一定时间内可以继续接收请求。 客户端浏览器解析HTML内容 客户端浏览器首先解析状态行，查看表明是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集，客户端浏览器读取响应数据HTML，根据HTML的语法来进行格式化，并在浏览器窗口进行显示。 浏览器输入地址URL，按下回车后会经历的流程 浏览器向DNS服务器请求解析该URL中的域名和所对应的IP地址 解析出IP地址之后，根据该IP地址和默认80端口，和服务器进行TCP连接 浏览器发出读取文件的HTTP请求，该请求报文作为TCP三次握手额第三个报文段的数据发送给服务器。 服务器对浏览器请求做出相应，并把对应的HTML文本发送给浏览器。 释放TCP连接 浏览器将该HTML文件解析并显示 DNS域名解析原理1、在浏览器中输入www.qq.com域名，操作系统会先**检查自己本地的hosts文件**是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 2、如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 3、如果hosts与本地DNS解析 器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的 域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 4、如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 5、如果本地DNS服务器本地区域文 件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务 器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负 责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址 (qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到 www.qq.com主机。 6、如果用的是转发模式，此DNS服 务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地 DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。 ARP（地址解析协议）协议原理​ 网络层以上的协议使用IP地址来标识网络接口，但是以太数据帧传输时，以物理地址来标识网络接口，因此我们需要进行IP地址与mac物理地址之间的转换。对于IPV4来说，我们使用ARP地址解析协议来进行IP地址与物理地址之间的转换。ARP协议提供了网络层地址到物理地址之间的转换。原理是通过广播来实现。 ​ ARP协议的工作原理如下： 每个主机都会在自己的ARP缓冲区中建立一个ARP列表，用于表示IP地址和MAC地址之间的对应关系。 主机新加入网络（可能是mac地址发生变化，接口重启）时，会自动将该ARP报文把自己的IP地址与MAC地址的映射关系广播给其他主机。 网络上的主机免费接收到ARP报文后，会更新自己的ARP列表缓冲区，将新的映射关系更新到自己的ARP列表 当某个主机需要发送报文时，首先检查ARP列表是否有对应的IP目的地址和目的主机的MAC地址，如果有，那就直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP 地址，源主机 MAC 地址，目的主机的 IP 地址等 。 当本网络的所有主机接收到该ARP数据包时： 检查数据包中的目的IP地址是否是自己的IP地址，如果不是，就忽略该数据包 如果是，就首先从数据包中取出源主机的目的IP地址和MAC地址更新到自己的ARP列表中，如果已经存在，就覆盖 将自己的MAC地址写入到响应包中，告诉源主机是它想要的MAC地址 源主机收到响应后，将目的主机的IP地址和MAC地址写入到ARP列表中，并利用此数据发送数据。如果源主机一直没有收到ARP的响应数据包，则表示ARP查询失败。 传输层传输层的作用：为应用层提供了通信服务 在OSI七层参考模型中，传输层是面向通信的最高层，也是用户功能的最底层。 传输层的两大功能：复用和分用 复用：在发送端，多个进程公用一个传输层 分用：在数据接收时，传输层会根据端口号的不同，将不同数据传输到不同应用中。 传输层和网络层的区别： ​ 网络层为不同主机提供了通信服务，而传输层为不同主机的不同应用提供了通信服务 ​ 网络层只对报文头部进行差错检测，而传输层则对整个报文进行差错检测 TCP报文段的结构中有6个标志字段。分别为ACK、RST、SYN、FIN、PSH和URG。 ACK：确认字段中的值是有效的，即该报文段包含一个对已被成功接收报文段的确认。 SYN：连接建立 FIN：连接拆除 TCP和UDP的区别是什么？​ tcp是面向连接的协议，在开始传输数据之前tcp客户端和服务器必须进行三次握手来保证连接的可用性，会话结束之后也要进行四次挥手，关闭连接。而udp是无连接的，无法保证数据是否能被收到。 ​ tcp保证数据按序发送按序到达，提供超时重传机制来保证可靠性，通过滑动窗口来实现 流量控制；而udp不保证按序到达，甚至不保证到达，只是努力交付。同时UDP也一直是以固定速率进行传输 ​ TCP协议所需资源多，TCP头部有20个字节，相反udp只有8个字节，udp协议传输量比tcp少 ​ TCP有流量控制和拥塞控制；而udp没有，网络阻塞不会影响发送端的发送效率 ​ tcp是一对一的连接；而udp可以实现多播和广播 ​ tcp是字节流的服务；而udp是面向报文的服务 ​ TCP包的大小是1460byte ​ UDP包的大小时1472byte ​ 用UDP协议发送时，用sendto函数最大能发送数据的长度为：65535- IP头(20) - UDP头(8)＝65507字节。用sendto函数发送数据时，如果发送数据长度大于该值，则函数会返回错误。 ​ 用TCP协议发送时，由于TCP是数据流协议，因此不存在包大小的限制（暂不考虑缓冲区的大小），这是指在用send函数时，数据长度参数不受限制。而实际上，所指定的这段数据并不一定会一次性发送出去，如果这段数据比较长，会被分段发送，如果比较短，可能会等待和下一次数据一起发送。 四次挥手​ 与建立连接的“三次握手”，断开一个TCP连接则需要“四次挥手”。 ​ 第一次挥手：主动关闭发送一个FIN，用来关闭主动方到被动关闭方的数据传输，也就是主动关闭方告诉被动关闭方，不会再给服务器发送数据了。 ​ 第二次挥手：被动关闭方收到FIN包后，发送一个ACK给对方，确认序号为(FIN+1),FIN为y。 ​ 第三次挥手：服务器发送一个FIN，用来关闭服务器到客户端的数据连接，此时会停止发送数据，同时会发一个FIN。 ​ 第四次挥手：客户端收到FIN，并发给服务器一个ACK给服务器，确认序号为收到的确认号+1 三次握手时，发送方再次发送确认的必要性？​ 主要是为了防止已失效的连接请求报文段突然又传到了服务器，因而产生错误。假定出现一种异常情况，client发出的第一个请求报文段没有丢失，而是在某些网络节点中长时间滞留了，一直延迟到连接释放后的某个时间点才到达服务器，本来这是一个早已失效的报文段。服务器收到请求连接报文段后，就误认为client又发出了一次新的连接请求，于是就想client发出确认报文段，同意建立连接,但此时客户端此时却根本不会理会服务器的同意连接请求，导致服务器一直等待客户端的连接，造成资源浪费。 TCP滑动窗口协议（连续ARQ协议）​ ARQ协议发送者每次只能发送一个分组，在应答到来之前必须等待，而连续ARQ协议的发送者拥有一个发送窗口，发送者可以在没有得到应答的情况下，连续发送窗口中的分组。这样就减少了等待时间，提高了传输效率。 ​ TCP滑动窗口实际上就是socket的接收缓冲区大小的字节数 流量控制​ 流量控制的根本目的是防止分组丢失，它是构成TCP可靠性的一面。如何实现流量控制？通过滑动窗口来实现。滑动窗口保证了分组无差错、有序接收，也实现了流量控制。 ​ TCP为它的应用程序提供了流量控制服务，以消除发送方使接收方缓存溢出的可能性。流量控制是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。 ​ TCP可能因为IP网络拥塞而被遏制，这种形式的发送方的控制被称为拥塞控制 TCP和UDP对应网络协议 ​ TCP：HTTP、Telnet、POP3、FTP、SMTP ​ UDP: DNS、SNMP、TPTP OSI七层模型 物理层…………… 数据链路层：物理寻址，将原始比特转变为逻辑传输 网络层：控制子网运行，同时将原始比特流转变为逻辑传输线路。通过路由选择算法，为报文或分组通过通信子网选择最合适的路径 传输层：数据传输，并保证数据段可靠到达 会话层：不同机器用户之间建立管理会话 表示层：加密、解密、压缩/解压缩 应用层：各种应用程序协议，比如HTTP、FTP、SMTP 四次挥手释放连接时，等待2msl（最长报文段寿命）的意义？ ​ 四次挥手释放连接后，客户端进行TIME_WAIT等待的原因是，客户端发送给服务器的ACK可能会导致丢失，而2msl是一个报文的最长生存周期。如果2msl之内发送的ACK发生丢失，就重新发一次ACK给服务器来正确关闭这个tcp连接。超过2msl后，服务器会自动关闭。 ​ 两个原因： 保证客户端发送的最后一个ACK报文能够到达服务器。由于这个ACK报文段可能会丢失，因而使处在last-check状态的服务器接收不到已发送的ACK响应。服务器会重新发送一个FIN+ACK，使得客户端能够在2MSL时间内收到这个重传的FIN+ACK。这样，就能保证服务器进行正常的步骤进入CLOSE状态。 A在发送完ACK报文段后，再经过2MSL时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失，使得下一个新的连接中不会出现这种旧的连接请求的报文段。 ACK：用于应答；SYN：主要起到同步的作用 ​ HTTP使用TCP作为它的支撑协议。HTTP客户首先发起一个与服务器的TCP连接。一旦建立连接，该浏览器和服务器进程就可以通过套接字接口访问TCP。TCP为HTTP提供了可靠数据服务。 ​ TCP状态机​ HTTP1.0、HTTP1.1和HTTP2.0HTTP1.0 : 是无连接、无状态的。浏览器的每次请求都需要与服务器建立一个新的连接，完成交互后立即断开。 HTTP1.1： 在HTTP1.0的基础上增加了持久连接(也称为长连接，在请求头中有keep_alive标志0) 实现了请求的管道化 增加了缓存处理(cache_control) 实现了分块传输 增加了Host字段，同时还实现了断点续传 HTTP2.0: 实现了二进制分帧 多路复用(连接共享) 头部压缩 服务器推送 HTTP2.0通讯都在一个TCP连接上实现，这个连接可以承载任意数量额双向数据流。 HTTP和HTTPS​ HTTPS在HTTP的基础上通过SSL安全套接字协议实现了数据传输的加密，客户端与服务器进行通讯需要提供一个CA（证书）。非对称加密 ​ HTTP的默认端口是80，而HTTPS的默认端口是443 ​ HTTPS就是加密的HTTP，HTTPS并不是一个新的协议，而是HTTP+SSL（TLS）。原本HTTP先和TCP直接通信，而加了SSL之后，就变成HTTP先和SSL通信，再由SSL和TCP通信，相当于SSL被嵌在了HTTP和TCP之间。 HTTPS的过程就是：在交互密钥阶段使用公开密钥加密方式，之后建立通信交换报文阶段则使用共享密钥加密方式。 服务器会把自己的公开密钥登录至数字证书认证机构 数字证书认证机构用自己的私有密钥向服务器的公开密码部署数字签名并颁发公钥证书 客户端拿到服务器的公钥证书之后，使用数字签名认证的公开密钥，向数字证书认证机构验证公钥证书上的数字签名，以确认服务器的公开密钥的正确性。 使用服务器的公开密钥对报文进行加密之后发送 服务器用私有的密钥进行数据的解密 9、设计模式设计模式六大设计原则​ 开闭原则：对拓展开放，对修改关闭 ​ 依赖注入：实现类依赖接口，而不是接口依赖于实现类 ​ 单一职责原则：一个接口应该只负责一个小模块，而不是负责处理所有请求 ​ 里氏替换原则：软件实体如果使用的是一个父类，那么一定使用与其子类 ​ 迪米特原则：如果两个类不必相互通讯，那么这两个类就不应该发生直接的引用。 代理模式(静态代理和动态代理)、依赖注入、抽象工厂和工厂 简单工厂：在创建对象时不向客户暴露内部细节，并提供一个创建对象的通用接口。 ​ 简单工厂把实例化的操作单独放到一个类中，这个类就成为了简单工厂类，让简单工厂类来决定应该用哪个具体子类来实例化。 ​ 这样做能把客户类和具体子类的实现解耦，客户类不再需要知道哪些子类以及应当实例化哪些子类。客户类往往有多个，如果不使用简单工厂，那么所有的客户类都要知道所有子类的细节。而且一旦子类发生改变，例如增加子类，那么所有的客户类都需要修改。 ​ 工厂方法：在简单工厂中，创建对象的是另一个类，而在工厂方法中，是由子类来创建对象。 抽象工厂：提供一个接口，用于创建相关的对象家族。抽象工厂创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂模式只是用于创建一个对象，这和抽象工厂模式有着很大的不同。抽象工厂模式用到了工厂模式来创建单一的对象。 建造者模式：封装一个对象的构造过程，并允许按照步骤来构造。 10、操作系统进程和线程的区别 线程调度（内核线程和用户线程，内核级线程还是用户级线程） ​ answer：对于用户级线程，内核不知道线程的存在，就给了线程很大的自主权。用户进程只是调度进程，进程中的调度程序选择哪个线程来运行。对于内核线程，线程的调度就交给了系统来完成。 线程通信 进程和线程通讯 线程的状态 进程调度算法（FIFO、时间片、优先级、短作业） 虚拟内存（分页和分段） 什么时候发生死锁？如何解决（破坏死锁产生的四大条件） 操作系统四大特性​ 并发、共享、虚拟化、异步 answer ​ 线程和进程的区别 ​ 资源分配与调度 ​ 进程是资源分配调度的基本单位，表示一个运行中的程序；而线程是cpu资源调度的基本单位，也是程序执行的最小单位。 ​ 时间与资源开销 ​ 进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段。而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程小很多，同时创建一个线程的资源消耗也远比进程小。 ​ 通信 ​ 线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式来进行。 ​ 健壮性 ​ 多进程程序更加健壮，多线程程序只要有一个死掉了，整个进程也就死掉了。而一个进程死掉并不会对另一个进程造成影响。 ​ 进程通信的几种方式 共享存储。几个进程共享某一内存区域，通过该内存区域的数据资源来进行交互。需要注意的是：该内存区域需要通过特殊的系统调用才能完成。 消息传递。1：直接通信：发送进程直接把消息发给接收进程。2：间接通信方式：发送进程把消息发送到某个中间体中，然后接收的进程来读取该中间体的内容。 管道通信：管道：连接一个读进程和一个写进程来实现它们之间通信的一个共享文件，又称为pipe文件。向管道提供输入的发送进程，以字符流形式将大量的数据送到写进程。管道必须提供以下的协调能力：互斥、同步和确定对方的存在。 进程调度 首先要从用户态转换到内核态 其次保存进程状态，包括当前进程状态，进程表中的存储寄存器 通过运行调度算法选择一个新进程，将新进程的内存映象装入到内存管理单元 新进程开始运行 切换过程包括：保存和装入寄存器值以及内存映像、更新各种表格和列表，、清除和重新调入内存的高速缓存。 用户态与内核态​ 内核态和用户态是现代操作系统中的两种工作模式。内核模块运行在内核空间中，而用户态运行在用户空间。它们代表不同的级别，而对系统资源具有不同的访问权限。内核模块运行在最高级别(内核态)，这个级别下所有的操作都受到系统信任，而应用程序运行在较低级别(用户态)。在这个级别下，处理器控制着对硬件的直接访问以及对内存的非授权访问。内核态和用户态都有自己的内存映射，即自己的内存空间。 ​ 用户空间的应用程序，通过系统调用，进入内核空间。由内核代表该进程运行与内核空间，这就涉及到上下文的切换，用户空间和内核空间具有不同的地址映射，通用或专用的寄存器组。由于用户空间的进程要传递很多变量、参数给内核，内核也要保存用户进程的一些寄存器、变量等，以便系统调用结束后回到用户空间继续执行。 ​ 用户态和内核态最重要的区别就是：相应特权级的不同，即权利的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。 ​ 用户态切换到内核态的三种方式： 系统调用。用户态进程通过系统调用申请使用操作系统提供的服务程序来完成工作。而系统调用的机制还是使用了操作系统为用户特别开放的一个中断来实现的。比如Linux的 int 80h中断。 异常：当CPU执行在用户态的程序下时，发生了某些事先不可预知的异常，这时候会触发当前运行进程切换到此异常的相关内核中，也就是转到了内核态，比如缺页异常。 外围设备的中断：当外围设备完成用户的请求之后，会向CPU发送相应的中断信号，这时CPU就会暂停执行下一条即将要执行的指令转而去执行与中断信号相应的处理程序。 进程的同步方案经典同步问题：生产者-消费者问题；哲学家进餐问题；读者-写者问题 同步的解决方案是：管程、信号量 线程调度 时间片调度 抢占式调度 死锁产生的四个必要条件 互斥条件：进程对所分配的资源进行排他性的调用(排他性) 请求和保持条件：进程被阻塞的时候并不释放锁申请到的资源 不可剥夺条件： 进程对于已经申请到的资源在使用完成之前不可以被剥夺 环路等待条件：发生死锁的时候存在一个进程-资源，环形等待链 死锁的处理 预防死锁：破坏死锁的4个必要条件的一个或者多个 避免死锁：在资源的动态分配中，防止系统进入不安全状态。（银行家算法） 检测死锁： 允许系统运行过程中产生死锁，死锁发生后，采用一定的算法进行检测，并确定与死锁相关的资源和进程，采取相关方法清除检测到的死锁。实现难度比较大。 解除死锁：与死锁检测配合，将系统从死锁中解脱出来，对检测到的死锁相关的进程和资源，通过撤销或者挂起的方式，释放一些资源并将其分配给处于阻塞状态的线程，使其转变为就绪态。 进程切换​ 进程切换是指从正在运行中的进程中收回处理器资源，让等待进程来占有处理器运行。实质上就是被中断进程与待运行进程的上下文切换。 ​ 进程切换必须在操作系统内核模式下完成，这就需要模式切换。模式切换又称为处理器切换，即用户模式与内核模式的切换。 ​ 尽管每个进程都有自己的地址空间，但是所有进程都必须共享CPU寄存器。因此，在恢复一个进程前，内核必须确保每个寄存器装载了挂起进程时所需要的值。 ​ 进程恢复之前必须装入寄存器的一组数据成为硬件上下文(hardware context)。硬件上下文是进程可执行上下文的一个自己，因为可执行上下文包括进程执行时所需要的所有信息。在linux中，进程硬件上下文的一部分存放在TSS段中，而剩余部分存放在内核态堆栈中。 ​ 进程切换的工作过程： (中断、异常等触发)正向模式切换并压入PSW/PC（PSW：程序状态字，PC：程序计数器） 保存被中断进程的现场信息。 处理具体中断、异常 把被中断进程的系统堆栈指针SP保存到PCB（SP：栈指针， PCB：程序控制块） 调整被中断进程的PCB信息，比如进程状态 把中断进程的PCB加入到相关队列 修改被选择进程的地址空间，恢复存储管理信息 恢复被选中进程的SP值到处理器寄存器SP 恢复被选中进程的现场信息进入到处理器 （中断返回指令触发）逆向模式转换并弹出PSW/PC 进程切换的发生场景： 阻塞式系统调用，虚拟地址异常。导致被中断进程进入到阻塞状态 时间片中断，I/O中断后发现更改优先级进程。导致被中断进程进入阻塞状态 终止用系统调用、不能继续执行的异常。导致中断进程进入终止态。 操作系统在处理中断时，并不一定会引发进程切换，有些中断处理完成之后，立即会恢复继续原进程的处理。 ​ 所谓的“进程上下文”，就是一个进程在执行的时候，CPU的所有寄存器的值、进程的状态以及堆栈上的内容。当内核需要切换到另一个进程时，需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时候的状态，继续执行。在linux中，当前进程上下文均保存在进程的任务数据结构中。在发生中断时，内核就能在被中断进程的上下文中，在内核态下执行中断服务例程。 ​ 内核有两种上下文：操作上下文和中断上下文。 进程调度算法​ 先来先服务、短作业优先、高响应比算法、时间片轮转算法、多级反馈队列调度算法 分段和分页的比较​ 把主存空间划分为大小相等的且固定的块，块相对较小，作为贮存的基本单位。每个进程也以块为单位进行划分，程序在执行时，以块为单位逐个申请主存中的块空间。因为程序数据存储在不同的页面上，页面又离散分布在内存中，因此需要一个页面来记录逻辑地址和实际存储地址的映射关系，从而实现页号到物理块号的转变。 ​ 分页是为了提高系统内存利用率，而分段则是为了满足程序员在编写代码的时候的一些逻辑需求（比如数据共享、数据保护、动态链接等）。 ​ 页是信息的物理单位，是出于系统内存利用率提出的离散分配机制；段是信息的逻辑单位，每个段含有一组意义完整的信息，是出于用户角度提出的内存管理机制。 ​ 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。 ​ 程序的地址空间划分为多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。 对程序员的透明性：分页透明，但是分段需要程序员显示划分每个段 地址空间的维度：页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使得程序和数据可以被划分为逻辑上的地址空间，并且有助于共享和保护。 虚拟内存​ 基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动执行。在程序的信息不在内存时，有操作系统将所需要的部分调入内存，然后继续执行程序。操作系统将内存中暂时不需要用的内容换出到外存中，从而腾出更多空间存放将要存入内存的信息。 ​ 虚拟内存技术的核心就是利用了局部性原理，把所要运行的进程中的数据不全部加载到内存中执行，而是加载一部分，当CPU在请求页表时，发现页表中的页表条目中的有效位为0但是被虚拟存储系统分配了的虚拟页时，就会把这个虚拟页从磁盘中调度到内存中（往往磁盘中的数据不常用，而在内存中的物理页的数据是频繁使用的数据），这样一来，我们就实现了多个进程同时加载到内存中并且还占用不是很多的内存的效果了 。 ​ 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。 为了更好地管理内存，操作系统将内存抽象为地址空间，每个程序都有自己的地址空间，这个地址空间被分为多个块，每一个块被称为一页。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页面时，由硬件执行必要的映射，将缺失的部分装入内存并重新执行失败的指令。 ​ 虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序称为可能。 守护、僵尸、孤儿进程​ 守护进程(Daemon)：运行在后台的一个特殊进程，独立于控制终端并周期性地执行某些任务 ​ 僵尸进程：一个进程fork子进程，子进程退出，而父进程没有wait/waitpid子进程，那么子进程的进程描述符仍保存在系统中，这样的进程被称为僵尸进程。 ​ 孤儿进程：一个父进程退出，而它的一个或者多个子进程还在运行，这些子进程被称为孤儿进程。孤儿进程将由init进程收养并对它们完成状态收集工作。 ​ ​ 11、分布式2pc、3pc cap、base paxos、zab 分布式缓存、session、消息队列 负载均衡、zookeeper 2PC：​ Two-Phase Commit(二阶段提交)。为了使基于分布式架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的算法。 ​ 2PC提交协议是将事务的提交过程分成两个阶段来进行的。 第一阶段： 事务询问：协调者将所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各个参与者的响应。 执行事务：各个参与者执行事务操作，并将Undo 和 Redo信息计入到事务日志中。 各个参与者向协调者反馈事务询问的响应。成功就返回yes，否则返回no。 第二阶段：​ 第二阶段执行事务的提交。根据参与者获得的反馈情况来决定最终是否可以进行事务提交操作。正常情况下，包括两种可能。 ​ 执行事务提交（所有节点都返回了yes响应）。 ​ 中断事务（任何一个参与者都向协调者反馈了No响应，或者等待超时后，协调者尚无法接受到所有参与者的反馈响应，那么就会中断事务）。中断过程如下： 发送回滚请求：协调者向所有的参与者发送RollBack回滚请求。 事务回滚：节点收到回滚请求之后，执行回滚操作，完成首释放所有执行期间所占用的资源 反馈事务回滚结果：完成之后，向协调者发送ACK消息。 中断事务：协调者完成事务中断 二阶段提交将事务的处理过程分为了投票和执行的处理逻辑。简单点讲，二阶段提交就是将事务的处理过程分为了投票和执行两个阶段。其核心是对每个事务都采取先尝试后提交的方式。因此可以将二阶段提交协议看做一个强一一致得算法。 ​ 优点：原理简单、实现方便 ​ 缺点：同步阻塞、单点问题、脑裂、太过保守 3PC​ Three-Phase Commit。 三阶段提交，是2PC的改进版，将二阶段提交协议的“提交事务请求”过程一分为二，形成了PreCommit和doCommit三个阶段组成的事务处理协议。 ​ 第一阶段：CanCommit 事务询问：协调者将所有的参与者发送一个包含事务请求内容的canCommit请求，询问是否可以执行事务提交操作，并等待参与者的响应。 各个参与者向协调者反馈事务询问的响应。如果可以提交事务，那么就返回yes，否则返回no。 ​ 第二阶段：PreCommit ​ 协调者根据各个参与者的反馈情况来决定是否可以进行事务的preCommit操作。如果协调者从所有参与者获得的都是yes，那么就会执行事务的preCommit。 ​ 如果协调者从所有参与者获得的都是yes，那么就会执行事务预提交。步骤有： 发送预提交请求 事务预提交 参与者向协调者反馈事务的响应 中断事务：任何一个参与者接收到了no，或者等待超时后，就会中断事务。步骤有： 发送中断请求 中断事务 第三阶段 doCommit​ 将进行真正的事务提交，有两种可能： ​ 执行提交：将进行真正的事务提交。过程有： 发送提交请求 事务提交 反馈事务提交结果 完成事务 优点：降低了参与者的阻塞范围，并且能够在出现单点问题后，继续达成一致。 缺点：去除阻塞的同时，也引入了新的问题，那就是在参与者接收到preCommit的消息后，如果出现网络分区，导致参与者与协调者无法进行正常的网络通讯，那么这个参与者依旧会进行事务提交，这必然导致数据的不一致性。 CAP理论​ 一个分布式系统不可能同时满足一致性(Consistency)、可用性(Availability)和分区容忍性(Partition tolerance)这三个需求，最多只能同时满足其中的两项。 ​ 一致性：数据在多个副本之间是否能保证一致性的特性。在一致性的需求下，一个系统在数据一致的情况下执行更新操作，应该保证系统的数据仍然处于一致的状态。 ​ 可用性：系统提供的服务必须一直处于可用的状态，对于用户的每一个操作总是在有限时间内返回结果。有限的时间是指：对于用户的一个操作请求，系统必须能够在指定时间内返回对应的处理结果，如果超过了这个时间范围，那么系统就会认为是不可用的。返回结果是指：系统在完成用户请求的处理之后，返回一个正常的响应结果。响应结果能够明确反映对请求的处理结果，即成功或者失败，而不是一个让用户感到困惑的结果。 ​ 分区容忍性：分布式系统在任何网络分区故障的时候，仍然需要保证对外提供满足一致性和可用性的服务，除非是整个网络都发生了故障。 ​ 对于一个分布式系统而言，分区容忍性是一个最基本的需求，它是一个分布式系统必须要解决的问题。因此系统架构师往往需要把精力花在根据业务特点在C(一致性)和A（可用性）之间寻求平衡。 ​ BASE理论​ BASE理论是Basically Avaliable（基本可用）、Soft state（软状态）和Eventually consistent(最终一致性)。 ​ BA（基本可用）：允许部分可用性，但不是系统不可用。包括两种状态： 响应时间上的损失 功能上的损失 ​ S （弱状态）：允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统存在不同节点之间数据副本之间进行数据同步的过程存在延迟。 E (最终一致性): 系统中所有的副本，在经过一段时间的同步后，最终能够达到一个一致的状态。其本质是系统保证最终一致性能够达到一致，而不需要实时保证系统数据的强一致性。最终一致性是一种特殊的弱一致性。系统能够保证在没有其他新的数据更新操作情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能获取到最新值。 Zookeeper​ Zookeeper是一个典型的分布式数据一致性的解决方案，分布式应用程序可以基于它实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列等功能。 ​ 和传统磁盘文件系统不同的是，Zookeeper将全部数据存储在内存中，以此来实现服务器吞吐、减少延迟的目的。只要集群中存在超过一半的机器能够正常工作，那么整个集群就不能够正常对外提供服务。 ​ Zookeeper的客户端程序会选择 和集群中任意一台机器共同来创建一个TCP连接，而一旦客户端和某台Zookeeper服务器之间断开后，客户端会自动连接到集群中的其他机器中。对于来自客户端的每个更新请求，Zookeeper都会分配一个全局唯一递增的编号，这个编号反映了所有事务操作的先后顺序，应用程序可以使用Zookeeper的这个特性来实现更高层次的同步原语。 Zookeeper将全部数据存储在内存中，并直接服务于客户端的所有非事务请求，因此它尤其适用于以读操作为主的应用场景。 Zookeeper没有沿用传统的Master/Slave模式，而是引入了Leader、Follower、Observer三种角色。Zookeeper集群中的所有机器通过一个Leader选举过程来选举一台被称为“Leader”的机器，，Leader为客户端提供读和写服务。Follower和Observer都能提供读服务，唯一的区别是，Observer机器不参与Leader的选举过程，也不参与写操作的“过半写成功”策略，因此Observer可以在不影响写性能的情况下提升集群的读性能。 Zookeeper的ZAB协议​ ZAB（Zookeeper AtomicBroadcast）协议是为分布式协调服务Zookeeper专门设计的一种支持崩溃恢复的原子广播协议。在Zookeeper中，主要依赖ZAB协议来实现分布式数据一致性。 ​ ZAB协议的核心定义：当整个集群在启动时，或者当leader节点出现网络中断、崩溃等情况时，ZAB协议就会进入恢复模式并选举出新的leader，当leader服务器选举出来后，并且集群中有过半的机器和这个leader服务器的状态保持一致，ZAB协议就会退出恢复模式。当集群中已经有过半的Follower节点完成了和Leader的状态同步后，那么整个集群就进入了消息广播模式。这个时候，在Leader节点正常工作时，启动一个新的服务器加入到集群，那这个服务器会直接进入数据恢复模式，和leader节点进行数据同步。同步完成之后就可以正常对外提供非事务请求的处理。 Zookeeper分布式锁​ 首先讲讲zookeeper的基本锁原理：利用临时节点与watch机制。每个锁占用一个普通节点/lock，当需要获取锁时，在lock目录下创建一个临时节点，创建成功则表示获取锁成功，失败则watch/lock节点，有删除操作后再去争取锁。临时节点的好处是，当进程挂掉后，能够自动上锁的节点自动删除即取消锁。 ​ zookeeper锁的缺点：所有获取锁失败的进程都监听父节点，很容易产生羊群效应，即当释放后所有等待进程一起创建节点，并发量很大。 ​ 优化：上锁改为创建临时有序节点，每个上锁的节点都能创建节点成功，只是其序号不同。只有序号最小的可以拥有锁，如果这个节点不是最小的，则watch序号比本身小的前一个节点（公平锁的实现）。 ​ 性能：没有缓存服务那么高，因为每次在创建锁和释放锁的过程中，都要动态创建、销毁临时节点来实现锁功能。Zookeeper中创建和删除节点只能通过Leader服务器来执行，然后将数据同步到所有的Follower机器上。 ​ SOA​ SOA是一种粗粒度、松耦合的以服务为中心的架构，接口之间通过定义明确的协议和接口来进行通信。SOA帮助工程师站在一个新的高度理解企业级架构中各种组件的开发和部署。 服务治理​ 服务治理就是独立于系统之外的，以服务模型最优化为目的的组织化行为。 ​ 12、算法​ 分治法： 将一个问题规模为n的问题，若该问题可以很容易地解决， 则直接解决。否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题格式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种的算法策略成为分治法。 ​ 动态规划（DP，Dynamic Programming）：动态规划的实质是分支思想和解决冗余，因此动态规划实际上是将问题实例分解为更小的、更相似的问题，并存储子问题的解从而避免计算重复的子问题，用来解决最优化的算法策略。动态规划都是将问题实例分解为更小的、相似的子问题，并通过求解子问题来产生一个全局最优解。其中，对于问题中的子问题如果都已选择，则采用贪心法来选取当前的最优解。 ​ 回溯法： ​ 贪心法： 13、IOjava中有哪几种类型的流？​ 字符流和字节流。字节流继承自InputStream和OutputStream。字符流继承自InputStreamReader和OutputStreamWriter。java io使用了两种设计模式：适配器模式和装饰器模式。 ​ 装饰器模式：由inputStream、outputStream和Reader和Writer的子类分别负责byte和插入流的根部。 一些流处理器可以对另一个流处理器起到装饰作用，形成新的、具有改善的功能的流处理器。 ​ 适配器模式：由inputstream、outputstream、reader和Writer代表的等级结构内部，有一些流处理器是对其他类型的流处理器的适配。这就是适配器的应用。 ​ 底层设备永远只接受字节数据。字符流是字节流的包装，字符流则是永远接受字符串，内部将字符串转成字节，再写入底层设备。 NIO​ NIO和BIO的区别： ​ BIO：面向流、阻塞式io ​ NIO：面向缓冲、非阻塞式IO、选择器。 ​ BIO和NIO的最大区别在于：IO是面向流的，NIO是面向缓冲区的。面向流意味着每次从流中读取一个或者多个字节，直至读取所有字节，它没有被缓存到任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。Java BIO的各种流是阻塞式的。这意味着，当一个线程调用read或者write时，该线程就会被阻塞，直到有一些数据被读取，或者数据完全写入，如果目前没有数据可以被获取，则阻塞。 ​ Java NIO是一种非阻塞模式的，一个线程从某个通道发送请求读取数据，但是它目前仅仅能够得到目前可用的数据，如果目前没有数据可以使用，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可用之前，该线程可以继续做其他的事情。一个线程请求写入一些数据到某个通道，但不需要等待它完全写入，这个线程可以去做别的事情。线程通常将非阻塞式io的空闲时间用在其他通道上执行io操作，所以一个单独的线程现在可以管理多个输入和输出通道。 ​ NIO可以只是用几个线程管理多个通道，但付出的代价是解析数据可能会比一个阻塞式流中读取数据更复杂。 ​ ​ JDK Selector是java的非阻塞式io实现的关键。它使用了事件通知API来确定一组非阻塞式套接字中有哪些已经就绪能够进行io相关的操作。因为在任何的时间检查任意的读操作或写操作的完成状态，因此一个单一的线程能够处理多个并发的连接。 ​ ​ Netty通过触发事件将Selector从应用程序中抽象出来，消除了本来需要手动编写的分发代码。在内部，将会为每个channel分配一个EventLoop，EventLoop对应于NIO中的一个线程，用以处理IO事件。一个EventLoop对应多个Channel，Channel对应于Socket 14、Linux​ top命令： 相当于windows的资源管理器，能够同台实时的显示系统种进程的资源占用情况。 Linux文件系统​ 文件存储在硬盘之上，硬盘的最小存储单元称为“扇区”，每个扇区存储512个字节(0.5KB)。操作系统读取硬盘时，不会一个个扇区地读取，这样效率太低，而是一次性地读取多个扇区，即一次性地读取一个块(block)。这种由多个扇区组成的块，是文件存储的最小单元。“块”的大小，最常见的是4KB，即连续八个sector组成的一个block。 ​ 文件数据都存储在“块”中，那么很显然，我们还必须找到一个地方存储文件的元信息，比如文件的创建者、创建日期、文件大小等。这种存储文件元信息的区域就叫做inode。中文名翻译为“索引节点”。 ​ 每一个文件都有对应的inode，里面包含了与该文件相关的一些信息。 ​ ​ inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统会自动将硬盘分为两个区域。一个是数据区，存放文件数据；另一个是inode区，存放inode所包含的信息。 ​ 每一个inode节点的大小，一般是128字节或者256字节。inode节点的总数，在格式化的时候就给定，一般是每1KB或者2KB就设置一个inode。假设在一块1GB的硬盘中，每个inode节点的大小是128字节，每1KB就设置一个inode，那么inode table的大小就是128MB，占整个磁盘的12.8%。 ​ 每个inode都对应一个唯一的文件id，来标识唯一的文件。操作系统通过inode的id来标识文件。 在unix/Linux系统中，目录也是一种文件。打开目录，实际上就是打开目录文件。目录文件的结构非常简单，就是一系列目录项的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名所对应的inode的id。 移动或者重命名文件，只是改变了文件名，而不会影响文件的inode。 分区在被linux文件系统（比如ext2）格式化的时候，就会分为inode table和block table两个部分，且大小都是固定的。该分区的inode都在inode table中，所有的block都在block table中。 文件系统如何存取文件？ 根据文件名，通过directory的对应关系，找到文件对应的Inode number 再根据Inode number读取到文件的Inode table 再根据Inode table的Pointer读取到相应的blocks ​ 15、其他计算机组成元素​ 计算机组成元素包括：输入设备、输出设备、运算器、控制器和存储器。其中存储器有包括内存和外存。在计算机断点时，内存中存储的数据会丢失，而外存则仍然能够保持数据存储。 == 和equals Runnable和Thread 刷leetcode wait、notify、notifyAll Restful docker和虚拟机区别 字节流和字符流 Bio和Nio、IO多路复用、Netty和Nio Servlet如何处理多个请求(web服务器启动，servlet就被加载并被实例化，servlet是单例的，初始化的过程就是读取配置文件)，request和response实例化过程，生成调用链，然后请求调用connector和container，http请求包装、然后经过调用链（用到了责任链模式），请求servlet，执行service方法。 linux打开一个read函数运行过程： ​ 从用户缓冲区到内存缓冲区，read操作，阻塞等待系统调用完成，io操作需要进行磁盘寻道，内存读取数据，写入缓冲区，调用返回。 Servlet的生命周期 加载和实例化 初始化 请求处理‘ 服务终止 ​ servlet容器是采用单实例多线程的方式来处理多个请求的。当web服务器启动时，servlet就被加载并实例化（只存在一个servlet实例） ​ 当请求到达时，servlet容器通过调度线程（Dispatcher Thread）调度它管理下线程池中等待执行的线程(Worker Thread)给请求者。 ​ 线程执行servlet的service方法、请求结束，放回线程池，等待被调用 CyclicBarrier和CountDownLatch的区别​ CountDownLatch是一个同步的辅助类，允许一个或者多个线程，等待其他一组线程完成操作，再进行操作 ​ CyclicBarrier是一个同步的辅助类，允许一组线程相互之间等待，达到一个共同点，再继续执行 Git和SVN区别 Git是分布式管理器，SVN不是 GIT把内容按照元数据方式存储，而SVN是按照文件 GIT分支和SVN分支不同 GIt没有全局的版本号，而SVN有 GIT的内容完整性要优于SVN。GIT的内容存储使用的是SHA1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题是降低对版本库的破坏。 ​ 克隆一份全新的目录以同样拥有五个分支来说，SVN是复制五个版本的文件，也就是说重复五次同样的动作。而GIT只是获取每个版本的元素，然后只载入主要的分支(Master)。 ​ SVN只能有一个指定的文明版本库，当这个中央版本有问题时候，所有工作成员都将一起瘫痪知道版本库维护完毕或者新的版本设立完成。而GIT可以有无限个版本库。 ​ 在SVN中，分支是一个完整的目录，且这个目录拥有完整的时间文件。如果工作文件成员想要开放新的分支，那将“污染全世界”。每个人都会拥有和你一样的分支。 Nginx​ Nginx的几种负载均衡策略： 轮询模式(默认)：每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能够自动剔除。 1234upstream backserver &#123; server 192.168.0.12; server 192.168.0.13;&#125; 指定权重：指定轮训几率，weight和访问比率成反比，用于后端服务器性能不均的情况。 1234upstream backserver &#123; server 192.168.0.12 weight=8; server 192.168.0.13 weight=10;&#125; ip绑定ip_hash:每个请求按照访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 12345upstream server &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:8080;&#125; fair（第三方）：按照后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream server &#123; server server1; server server2; fair;&#125; url_hash:按照访问url的hash结果来分配请求，使得每个url定向到同一个url后端服务器，后端服务器为缓存时比较有效。123456upstream server &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32;&#125; DubboDubbo的负载均衡​ 在集群负载均衡时，dubbo提供了多种均衡策略，缺省时为random随机调用。 Random LoadBalance ：随机，按权重设置随机概率。在一个截面上碰撞的概率比较大，但调用量越大分布越均匀，而且按照概率使用权重之后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance : 轮训，按公约后的权重设置轮训比例比率。存在慢的提供者累积请求问题。比如，第二台机器很慢，但没挂，当请求调至第二台就卡在那，久而久之，所有请求都卡在调用第二台上。 LeastActive LoadBalance : 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使最慢的提供者收到更少的请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance: 一致性hash。 相同参数的请求总是发到同一个提供者。当某一台提供者挂掉时，原本要发往该提供者的请求，基于虚拟节点，平摊到其他提供者，不会引起剧烈变动。 Dubbo的结果缓存​ 结果缓存，用于加速热门数据的访问速度，Dubbo提供声明式缓存，用于减少用户加缓存的工作量。 ​ 缓存类型有： LRU：最近最少使用 threadlocal：当前线程缓存，比如渲染一个页面 jcache HDFSHDFS文件block​ 物理磁盘中有块的概念，磁盘的block是磁盘操作最小的单元，读写操作均以block为最小单元，一般为512byte，0.5kb。文件系统在物理block之上抽象了另外一层概念，文件系统block是物理磁盘block的整数倍，通常为几kb。Hadoop提供的df、fsck这类运维工具都是在文件系统的Block级别之上进行的操作。 ​ ​ HDFS的block块比一般单机文件系统大得多，默认为128M。HDFS的文件被拆分为block-sized的chunk，chunk作为独立单元存储。比block小的文件不会占用整个Block，只会占据实际大小。 为什么HDFS文件的Block这么大？​ 是为了最小化查找(seek)时间，控制定位文件与传输文件所用的事件比例。假设定位到block所需的时间为10ms，磁盘传输速度为100m/s。如果要将定位到block块的时间控制在总时间的1%，则block大小需要为100M。但是如果block设置过大，在MapReduce任务中，Map或者reduce任务的个数小于集群机器数量，则会使得作业运行效率很低。 block抽象的好处​ block的拆分使得单个文件大小可以大于整个磁盘的容量大小，构成文件的Block可以分布在整个集群，理论上，单个文件可以占据集群中所有机器的磁盘。 ​ Block的抽象也简化了存储系统，对于block，无需关注其权限、所有者的问题（这些问题都在文件级别上进行控制）。Block作为容错和高可用机制的副本单元，以Block块为单位进行复制。 ​ 整个HDFS集群由namenode和Datanode构成master-worker(主从)模式。namenode负责构建命名空间，管理文件的元数据等，而Datanode负责实际存储数据，负责读写工作。Namenode存放文件系统树以及所有文件、目录的元数据。namenode在内存中保存着文件系统中每个文件和每个数据块的引用关系，这意味着对于一个拥有大量文件的超大集群来说，内存将成为限制系统横向拓展的瓶颈。 ​ DataNode：数据节点负责存储和读取Block，读写请求可能来自namenode，也有可能直接来自客户端。数据节点周期性向Namenode汇报自己节点上所存储的Block相关信息。在系统中有一个称为故障转移控制器，管理着将活动namenode转移为备用namenode的转换过程。有多种故障转移，默认使用的是使用了Zookeeper来确保有且仅有一个活动namenode。每一个namenode运行着一个轻量级的故障转移控制器，其工作就是监视宿主namenode是否失效并在namenode失效时进行故障切换。 ​ ###","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-08-24T14:53:48.744Z","updated":"2019-08-24T14:53:48.745Z","comments":true,"path":"2019/08/24/hello-world/","link":"","permalink":"http://yoursite.com/2019/08/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}